{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction - nasdaq100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price     Volume\n",
      "0  02-Jan-2009     1212.74      1263.70     1266.45    1208.91  248576128\n",
      "1  05-Jan-2009     1254.70      1262.52     1274.11    1244.89  298954208\n",
      "2  06-Jan-2009     1274.36      1274.49     1286.08    1265.53  343802624\n",
      "3  07-Jan-2009     1249.98      1238.60     1256.34    1228.32  388103616\n",
      "4  08-Jan-2009     1231.75      1252.52     1252.52    1223.81  326125920\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './nasdaq-train.csv'\n",
    "test_data_path = './nasdaq-test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 4)\n",
      "   Open Price  Close Price  High Price  Low Price\n",
      "0     1212.74      1263.70     1266.45    1208.91\n",
      "1     1254.70      1262.52     1274.11    1244.89\n",
      "2     1274.36      1274.49     1286.08    1265.53\n",
      "3     1249.98      1238.60     1256.34    1228.32\n",
      "4     1231.75      1252.52     1252.52    1223.81\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "train_df.drop(columns=['Date', 'Volume'], inplace=True) # , 'Volume', 'High Price', 'Low Price'\n",
    "test_df.drop(columns=['Date', 'Volume'], inplace=True) # , 'Volume', 'High Price', 'Low Price'\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price  Tomorrow Movement  \\\n",
      "0     1212.74      1263.70     1266.45    1208.91                0.0   \n",
      "1     1254.70      1262.52     1274.11    1244.89                1.0   \n",
      "2     1274.36      1274.49     1286.08    1265.53                0.0   \n",
      "3     1249.98      1238.60     1256.34    1228.32                1.0   \n",
      "4     1231.75      1252.52     1252.52    1223.81                0.0   \n",
      "\n",
      "   Tomorrow Open  \n",
      "0        1254.70  \n",
      "1        1274.36  \n",
      "2        1249.98  \n",
      "3        1231.75  \n",
      "4        1252.60  \n",
      "      Open Price  Close Price  High Price  Low Price  Tomorrow Movement  \\\n",
      "2258     6462.55      6465.17     6467.83    6449.00                0.0   \n",
      "2259     6427.32      6433.16     6438.24    6407.99                1.0   \n",
      "2260     6437.06      6435.15     6448.94    6425.92                1.0   \n",
      "2261     6449.52      6441.42     6452.07    6432.68                0.0   \n",
      "2262     6439.90      6396.42     6442.53    6396.42                NaN   \n",
      "\n",
      "      Tomorrow Open  \n",
      "2258        6427.32  \n",
      "2259        6437.06  \n",
      "2260        6449.52  \n",
      "2261        6439.90  \n",
      "2262            NaN  \n"
     ]
    }
   ],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with previous days as the training target\n",
    "# Add the column `Tomorrow Open` by shifting the column `Open Price` as one of the new features\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)\n",
    "\n",
    "train_df['Tomorrow Open'] = train_df['Open Price'].shift(-1)\n",
    "test_df['Tomorrow Open'] = test_df['Open Price'].shift(-1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2244, 10)\n",
      "    Open Price  Close Price  High Price  Low Price  Tomorrow Movement  \\\n",
      "18     1217.75      1203.85     1220.72    1198.76                0.0   \n",
      "19     1212.31      1180.25     1216.46    1176.82                1.0   \n",
      "20     1168.13      1195.75     1203.53    1167.49                1.0   \n",
      "21     1198.79      1215.66     1218.91    1180.25                0.0   \n",
      "22     1215.64      1215.43     1243.68    1210.98                1.0   \n",
      "\n",
      "    Tomorrow Open      S_10      Corr  Open-Close  Open-Open  \n",
      "18        1212.31  1186.673 -0.278443      -18.16       3.91  \n",
      "19        1168.13  1186.346 -0.309854        8.46      -5.44  \n",
      "20        1198.79  1186.107 -0.665739      -12.12     -44.18  \n",
      "21        1215.64  1194.012 -0.105050        3.04      30.66  \n",
      "22        1200.26  1196.979  0.180301       -0.02      16.85  \n",
      "(233, 10)\n",
      "    Open Price  Close Price  High Price  Low Price  Tomorrow Movement  \\\n",
      "18     7000.68      6988.32     7020.64    6974.70                0.0   \n",
      "19     6910.39      6930.73     6958.79    6894.63                1.0   \n",
      "20     6972.81      6949.99     6983.61    6915.48                0.0   \n",
      "21     6910.57      6901.50     6970.76    6879.02                0.0   \n",
      "22     6866.38      6760.29     6889.07    6756.54                0.0   \n",
      "\n",
      "    Tomorrow Open      S_10      Corr  Open-Close  Open-Open  \n",
      "18        6910.39  6890.981  0.935212      -22.29      44.02  \n",
      "19        6972.81  6910.340  0.832747      -77.93     -90.29  \n",
      "20        6910.57  6924.311  0.745610       42.08      62.42  \n",
      "21        6866.38  6933.323  0.457512      -39.42     -62.24  \n",
      "22        6687.47  6925.919 -0.212111      -35.12     -44.19  \n"
     ]
    }
   ],
   "source": [
    "# Add other new features `S_10`, `Corr`, `Open-Close`, `Open-Open` (explanation is described below)\n",
    "\n",
    "train_df['S_10'] = train_df['Close Price'].rolling(window=10).mean()\n",
    "train_df['Corr'] = train_df['Close Price'].rolling(window=10).corr(train_df['S_10'])\n",
    "train_df['Open-Close'] = train_df['Open Price'] - train_df['Close Price'].shift(1)\n",
    "train_df['Open-Open'] = train_df['Open Price'] - train_df['Open Price'].shift(1)\n",
    "train_df = train_df.dropna()\n",
    "new_train_df = train_df.iloc[:,:10]\n",
    "\n",
    "print(new_train_df.shape)\n",
    "print(new_train_df.head())\n",
    "\n",
    "test_df['S_10'] = test_df['Close Price'].rolling(window=10).mean()\n",
    "test_df['Corr'] = test_df['Close Price'].rolling(window=10).corr(test_df['S_10'])\n",
    "test_df['Open-Close'] = test_df['Open Price'] - test_df['Close Price'].shift(1)\n",
    "test_df['Open-Open'] = test_df['Open Price'] - test_df['Open Price'].shift(1)\n",
    "test_df = test_df.dropna()\n",
    "new_test_df = test_df.iloc[:,:10]\n",
    "\n",
    "print(new_test_df.shape)\n",
    "print(new_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2244, 9)\n",
      "    Open Price  Close Price  High Price  Low Price  Tomorrow Open      S_10  \\\n",
      "18     1217.75      1203.85     1220.72    1198.76        1212.31  1186.673   \n",
      "19     1212.31      1180.25     1216.46    1176.82        1168.13  1186.346   \n",
      "20     1168.13      1195.75     1203.53    1167.49        1198.79  1186.107   \n",
      "21     1198.79      1215.66     1218.91    1180.25        1215.64  1194.012   \n",
      "22     1215.64      1215.43     1243.68    1210.98        1200.26  1196.979   \n",
      "\n",
      "        Corr  Open-Close  Open-Open  \n",
      "18 -0.278443      -18.16       3.91  \n",
      "19 -0.309854        8.46      -5.44  \n",
      "20 -0.665739      -12.12     -44.18  \n",
      "21 -0.105050        3.04      30.66  \n",
      "22  0.180301       -0.02      16.85  \n",
      "(2244,)\n",
      "18    0.0\n",
      "19    1.0\n",
      "20    1.0\n",
      "21    0.0\n",
      "22    1.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(233, 9)\n",
      "    Open Price  Close Price  High Price  Low Price  Tomorrow Open      S_10  \\\n",
      "18     7000.68      6988.32     7020.64    6974.70        6910.39  6890.981   \n",
      "19     6910.39      6930.73     6958.79    6894.63        6972.81  6910.340   \n",
      "20     6972.81      6949.99     6983.61    6915.48        6910.57  6924.311   \n",
      "21     6910.57      6901.50     6970.76    6879.02        6866.38  6933.323   \n",
      "22     6866.38      6760.29     6889.07    6756.54        6687.47  6925.919   \n",
      "\n",
      "        Corr  Open-Close  Open-Open  \n",
      "18  0.935212      -22.29      44.02  \n",
      "19  0.832747      -77.93     -90.29  \n",
      "20  0.745610       42.08      62.42  \n",
      "21  0.457512      -39.42     -62.24  \n",
      "22 -0.212111      -35.12     -44.19  \n",
      "(233,)\n",
      "18    0.0\n",
      "19    1.0\n",
      "20    0.0\n",
      "21    0.0\n",
      "22    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "data_train_x = new_train_df.drop(columns=['Tomorrow Movement'])\n",
    "data_train_y = new_train_df['Tomorrow Movement']\n",
    "\n",
    "data_test_x = new_test_df.drop(columns=['Tomorrow Movement'])\n",
    "data_test_y = new_test_df['Tomorrow Movement']\n",
    "\n",
    "print(data_train_x.shape)\n",
    "print(data_train_x.head())\n",
    "print(data_train_y.shape)\n",
    "print(data_train_y.head())\n",
    "print('-----')\n",
    "print(data_test_x.shape)\n",
    "print(data_test_x.head())\n",
    "print(data_test_y.shape)\n",
    "print(data_test_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.6898395721925134\n",
      "\n",
      "testing accuracy:\n",
      "0.6952789699570815\n",
      "\n",
      "testing result prob:\n",
      "[[9.83707414e-01 1.62925864e-02]\n",
      " [1.11451883e-01 8.88548117e-01]\n",
      " [8.54733435e-01 1.45266565e-01]\n",
      " [8.92634315e-01 1.07365685e-01]\n",
      " [9.87583615e-01 1.24163851e-02]\n",
      " [9.99354735e-01 6.45265353e-04]\n",
      " [9.86999995e-01 1.30000054e-02]\n",
      " [2.26313089e-01 7.73686911e-01]\n",
      " [5.94565977e-03 9.94054340e-01]\n",
      " [7.61714038e-02 9.23828596e-01]\n",
      " [8.97943846e-01 1.02056154e-01]\n",
      " [8.87045941e-01 1.12954059e-01]\n",
      " [4.43754147e-02 9.55624585e-01]\n",
      " [6.01058722e-01 3.98941278e-01]\n",
      " [7.66233154e-01 2.33766846e-01]\n",
      " [1.46179898e-01 8.53820102e-01]\n",
      " [6.33552587e-02 9.36644741e-01]\n",
      " [2.87746373e-02 9.71225363e-01]\n",
      " [8.40213940e-02 9.15978606e-01]\n",
      " [3.88180216e-01 6.11819784e-01]\n",
      " [3.89168085e-02 9.61083192e-01]\n",
      " [2.50096423e-01 7.49903577e-01]\n",
      " [9.94580544e-01 5.41945615e-03]\n",
      " [9.61076871e-01 3.89231286e-02]\n",
      " [1.14895242e-01 8.85104758e-01]\n",
      " [9.38354582e-01 6.16454180e-02]\n",
      " [2.51787669e-01 7.48212331e-01]\n",
      " [3.87681756e-02 9.61231824e-01]\n",
      " [1.60079303e-01 8.39920697e-01]\n",
      " [4.00611179e-02 9.59938882e-01]\n",
      " [6.88750963e-02 9.31124904e-01]\n",
      " [3.00629747e-01 6.99370253e-01]\n",
      " [1.34280212e-01 8.65719788e-01]\n",
      " [9.78789118e-01 2.12108819e-02]\n",
      " [6.03078881e-01 3.96921119e-01]\n",
      " [8.30738964e-01 1.69261036e-01]\n",
      " [9.95248237e-01 4.75176280e-03]\n",
      " [6.63011872e-01 3.36988128e-01]\n",
      " [4.96061130e-04 9.99503939e-01]\n",
      " [1.34492127e-01 8.65507873e-01]\n",
      " [8.83324860e-01 1.16675140e-01]\n",
      " [2.86238156e-01 7.13761844e-01]\n",
      " [9.64554823e-01 3.54451766e-02]\n",
      " [5.17619610e-02 9.48238039e-01]\n",
      " [9.99640369e-01 3.59630797e-04]\n",
      " [1.34947603e-01 8.65052397e-01]\n",
      " [9.75382892e-01 2.46171083e-02]\n",
      " [5.86406775e-02 9.41359322e-01]\n",
      " [7.95554673e-04 9.99204445e-01]\n",
      " [8.06878000e-01 1.93122000e-01]\n",
      " [6.53804571e-02 9.34619543e-01]\n",
      " [5.79367328e-02 9.42063267e-01]\n",
      " [3.86604904e-02 9.61339510e-01]\n",
      " [1.83612410e-02 9.81638759e-01]\n",
      " [2.46982453e-01 7.53017547e-01]\n",
      " [8.48988680e-01 1.51011320e-01]\n",
      " [7.37686235e-01 2.62313765e-01]\n",
      " [1.33400393e-01 8.66599607e-01]\n",
      " [1.19151032e-01 8.80848968e-01]\n",
      " [4.09388366e-01 5.90611634e-01]\n",
      " [1.00875028e-02 9.89912497e-01]\n",
      " [2.12132764e-03 9.97878672e-01]\n",
      " [1.82746332e-01 8.17253668e-01]\n",
      " [6.73489746e-01 3.26510254e-01]\n",
      " [4.51322506e-01 5.48677494e-01]\n",
      " [8.34084777e-01 1.65915223e-01]\n",
      " [8.84879567e-01 1.15120433e-01]\n",
      " [1.75274588e-01 8.24725412e-01]\n",
      " [4.19478837e-01 5.80521163e-01]\n",
      " [2.71462150e-01 7.28537850e-01]\n",
      " [2.45025970e-01 7.54974030e-01]\n",
      " [5.72395181e-01 4.27604819e-01]\n",
      " [1.37836644e-01 8.62163356e-01]\n",
      " [9.22285271e-01 7.77147291e-02]\n",
      " [4.87223154e-01 5.12776846e-01]\n",
      " [7.62692512e-01 2.37307488e-01]\n",
      " [7.87945412e-01 2.12054588e-01]\n",
      " [4.20939170e-02 9.57906083e-01]\n",
      " [1.05532679e-01 8.94467321e-01]\n",
      " [9.16824183e-01 8.31758173e-02]\n",
      " [6.91890949e-01 3.08109051e-01]\n",
      " [4.65532454e-01 5.34467546e-01]\n",
      " [8.42552837e-01 1.57447163e-01]\n",
      " [1.69412643e-01 8.30587357e-01]\n",
      " [5.08973554e-01 4.91026446e-01]\n",
      " [5.72116521e-02 9.42788348e-01]\n",
      " [2.06390922e-01 7.93609078e-01]\n",
      " [1.57748931e-01 8.42251069e-01]\n",
      " [2.00214107e-01 7.99785893e-01]\n",
      " [3.88829976e-01 6.11170024e-01]\n",
      " [8.04242950e-01 1.95757050e-01]\n",
      " [5.78215134e-01 4.21784866e-01]\n",
      " [2.46119789e-01 7.53880211e-01]\n",
      " [2.74213538e-01 7.25786462e-01]\n",
      " [1.04104617e-01 8.95895383e-01]\n",
      " [8.26698512e-01 1.73301488e-01]\n",
      " [9.55581248e-01 4.44187517e-02]\n",
      " [9.96359529e-01 3.64047142e-03]\n",
      " [1.82983992e-01 8.17016008e-01]\n",
      " [1.13885667e-01 8.86114333e-01]\n",
      " [1.45530972e-01 8.54469028e-01]\n",
      " [9.75832087e-01 2.41679130e-02]\n",
      " [3.68628575e-01 6.31371425e-01]\n",
      " [1.77517368e-01 8.22482632e-01]\n",
      " [5.09552003e-01 4.90447997e-01]\n",
      " [1.41791628e-01 8.58208372e-01]\n",
      " [9.50177553e-01 4.98224468e-02]\n",
      " [3.56754900e-01 6.43245100e-01]\n",
      " [3.04353838e-02 9.69564616e-01]\n",
      " [3.09663921e-01 6.90336079e-01]\n",
      " [6.83685892e-02 9.31631411e-01]\n",
      " [2.30493061e-01 7.69506939e-01]\n",
      " [9.59138202e-01 4.08617980e-02]\n",
      " [1.59480572e-01 8.40519428e-01]\n",
      " [3.34439936e-01 6.65560064e-01]\n",
      " [2.93692730e-01 7.06307270e-01]\n",
      " [9.66503322e-01 3.34966782e-02]\n",
      " [5.69341213e-01 4.30658787e-01]\n",
      " [7.14268426e-01 2.85731574e-01]\n",
      " [1.57784660e-01 8.42215340e-01]\n",
      " [5.93566030e-01 4.06433970e-01]\n",
      " [9.59680618e-03 9.90403194e-01]\n",
      " [2.94244706e-01 7.05755294e-01]\n",
      " [9.97764704e-01 2.23529621e-03]\n",
      " [1.03759162e-01 8.96240838e-01]\n",
      " [4.80050464e-01 5.19949536e-01]\n",
      " [2.48320631e-01 7.51679369e-01]\n",
      " [1.20280489e-01 8.79719511e-01]\n",
      " [9.37818150e-01 6.21818496e-02]\n",
      " [4.22643815e-01 5.77356185e-01]\n",
      " [4.47217810e-01 5.52782190e-01]\n",
      " [2.26271840e-01 7.73728160e-01]\n",
      " [4.90697142e-01 5.09302858e-01]\n",
      " [4.91794134e-01 5.08205866e-01]\n",
      " [9.52601928e-01 4.73980719e-02]\n",
      " [3.88765878e-01 6.11234122e-01]\n",
      " [1.08876900e-01 8.91123100e-01]\n",
      " [9.66767254e-01 3.32327456e-02]\n",
      " [6.44454631e-02 9.35554537e-01]\n",
      " [7.11387993e-01 2.88612007e-01]\n",
      " [3.89145263e-01 6.10854737e-01]\n",
      " [2.11706170e-01 7.88293830e-01]\n",
      " [6.87204507e-01 3.12795493e-01]\n",
      " [6.06876650e-01 3.93123350e-01]\n",
      " [1.22494416e-01 8.77505584e-01]\n",
      " [6.56645296e-02 9.34335470e-01]\n",
      " [1.48218551e-01 8.51781449e-01]\n",
      " [1.95481453e-01 8.04518547e-01]\n",
      " [6.37432580e-01 3.62567420e-01]\n",
      " [4.91522803e-01 5.08477197e-01]\n",
      " [7.51987424e-01 2.48012576e-01]\n",
      " [7.58993221e-01 2.41006779e-01]\n",
      " [4.36761112e-01 5.63238888e-01]\n",
      " [9.58448658e-01 4.15513420e-02]\n",
      " [1.69141487e-01 8.30858513e-01]\n",
      " [8.55163663e-01 1.44836337e-01]\n",
      " [8.15109766e-01 1.84890234e-01]\n",
      " [7.80838218e-02 9.21916178e-01]\n",
      " [2.48438980e-01 7.51561020e-01]\n",
      " [7.66531130e-01 2.33468870e-01]\n",
      " [4.25735397e-01 5.74264603e-01]\n",
      " [4.75584657e-01 5.24415343e-01]\n",
      " [7.01989499e-02 9.29801050e-01]\n",
      " [1.97387518e-01 8.02612482e-01]\n",
      " [9.34246912e-01 6.57530884e-02]\n",
      " [6.16410719e-01 3.83589281e-01]\n",
      " [4.27667043e-01 5.72332957e-01]\n",
      " [7.06815390e-02 9.29318461e-01]\n",
      " [6.01304734e-01 3.98695266e-01]\n",
      " [5.46766710e-02 9.45323329e-01]\n",
      " [5.05650859e-01 4.94349141e-01]\n",
      " [9.61003755e-02 9.03899625e-01]\n",
      " [8.05138624e-01 1.94861376e-01]\n",
      " [6.87259655e-01 3.12740345e-01]\n",
      " [9.52059742e-01 4.79402578e-02]\n",
      " [7.05973523e-01 2.94026477e-01]\n",
      " [9.54252395e-01 4.57476048e-02]\n",
      " [8.91420714e-01 1.08579286e-01]\n",
      " [6.84182395e-05 9.99931582e-01]\n",
      " [7.49557967e-01 2.50442033e-01]\n",
      " [1.85715708e-02 9.81428429e-01]\n",
      " [1.18241536e-01 8.81758464e-01]\n",
      " [7.62209459e-01 2.37790541e-01]\n",
      " [5.16155067e-02 9.48384493e-01]\n",
      " [7.44567937e-02 9.25543206e-01]\n",
      " [9.99599074e-01 4.00926281e-04]\n",
      " [9.28506344e-01 7.14936561e-02]\n",
      " [2.27300664e-03 9.97726993e-01]\n",
      " [9.99996242e-01 3.75843753e-06]\n",
      " [1.19705860e-02 9.88029414e-01]\n",
      " [8.88026141e-01 1.11973859e-01]\n",
      " [3.19508121e-03 9.96804919e-01]\n",
      " [1.10743104e-01 8.89256896e-01]\n",
      " [8.35252495e-01 1.64747505e-01]\n",
      " [7.30398615e-01 2.69601385e-01]\n",
      " [5.84578363e-01 4.15421637e-01]\n",
      " [9.80496980e-03 9.90195030e-01]\n",
      " [7.41946558e-01 2.58053442e-01]\n",
      " [9.65274311e-01 3.47256889e-02]\n",
      " [9.64198514e-01 3.58014858e-02]\n",
      " [2.10366347e-01 7.89633653e-01]\n",
      " [2.42749799e-02 9.75725020e-01]\n",
      " [7.03025868e-01 2.96974132e-01]\n",
      " [9.93247893e-01 6.75210691e-03]\n",
      " [9.18640228e-01 8.13597719e-02]\n",
      " [9.99947098e-01 5.29019676e-05]\n",
      " [5.94061800e-02 9.40593820e-01]\n",
      " [9.07075035e-01 9.29249655e-02]\n",
      " [7.81400933e-03 9.92185991e-01]\n",
      " [8.58115423e-01 1.41884577e-01]\n",
      " [5.24440662e-02 9.47555934e-01]\n",
      " [7.66105132e-01 2.33894868e-01]\n",
      " [2.79761721e-01 7.20238279e-01]\n",
      " [9.60647447e-05 9.99903935e-01]\n",
      " [6.33913428e-01 3.66086572e-01]\n",
      " [1.49633703e-06 9.99998504e-01]\n",
      " [9.99256471e-01 7.43528803e-04]\n",
      " [9.80369812e-01 1.96301882e-02]\n",
      " [5.91200402e-01 4.08799598e-01]\n",
      " [9.90620178e-03 9.90093798e-01]\n",
      " [2.24885786e-03 9.97751142e-01]\n",
      " [4.38122560e-02 9.56187744e-01]\n",
      " [9.92992820e-01 7.00717972e-03]\n",
      " [8.85930720e-01 1.14069280e-01]\n",
      " [6.09388278e-02 9.39061172e-01]\n",
      " [6.57189655e-01 3.42810345e-01]\n",
      " [8.66137281e-01 1.33862719e-01]\n",
      " [1.11187492e-01 8.88812508e-01]\n",
      " [9.52219790e-01 4.77802098e-02]\n",
      " [4.56924334e-02 9.54307567e-01]\n",
      " [9.98407348e-01 1.59265196e-03]\n",
      " [2.30874213e-01 7.69125787e-01]\n",
      " [9.53440886e-03 9.90465591e-01]]\n",
      "\n",
      "predicted testing labels:\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "#lr_model = SGDClassifier(loss='log',  max_iter=800)\n",
    "lr_model.fit(data_train_x, data_train_y)\n",
    "\n",
    "predict_train_y = lr_model.predict(data_train_x)\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(data_train_y, predict_train_y))\n",
    "\n",
    "lr_predict_test_y = lr_model.predict(data_test_x)\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(data_test_y, lr_predict_test_y))\n",
    "\n",
    "print('\\ntesting result prob:')\n",
    "print(lr_model.predict_proba(data_test_x))\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.6953338947871519, 0.6952789699570815, 0.6942611409862763, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(71, 40, 31, 91)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(data_test_y, lr_predict_test_y, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(data_test_y, lr_predict_test_y).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Close Price      Corr  High Price  Low Price  Open Price  Open-Close  \\\n",
      "0    -0.855107 -1.025865   -0.850094  -0.855701   -0.851757   -1.067904   \n",
      "1    -0.866038 -1.065955   -0.852062  -0.865924   -0.854285    0.363856   \n",
      "2    -0.858859 -1.520172   -0.858036  -0.870271   -0.874822   -0.743042   \n",
      "3    -0.849637 -0.804563   -0.850930  -0.864326   -0.860570    0.072341   \n",
      "4    -0.849744 -0.440368   -0.839486  -0.850008   -0.852738   -0.092241   \n",
      "\n",
      "   Open-Open      S_10  Tomorrow Open  \n",
      "0  -0.017558 -0.844289      -0.857295  \n",
      "1  -0.291170 -0.844440      -0.877831  \n",
      "2  -1.424830 -0.844551      -0.863579  \n",
      "3   0.765235 -0.840887      -0.855747  \n",
      "4   0.361109 -0.839511      -0.862896  \n",
      "[-1  1  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(data_train_x) #scaler.fit(train_df.append(test_df, ignore_index=True))\n",
    "\n",
    "train_normalize = scaler.transform(data_train_x)\n",
    "train_normalize = np.transpose(train_normalize)\n",
    "\n",
    "normalize_train_x = pd.DataFrame({\n",
    "    'Open Price': train_normalize[0],\n",
    "    'Close Price': train_normalize[1],\n",
    "    'High Price': train_normalize[2],\n",
    "    'Low Price': train_normalize[3],\n",
    "    'Tomorrow Open': train_normalize[4],\n",
    "    'S_10': train_normalize[5],\n",
    "    'Corr': train_normalize[6],\n",
    "    'Open-Close': train_normalize[7],\n",
    "    'Open-Open': train_normalize[8],\n",
    "})\n",
    "\n",
    "test_normalize = scaler.transform(data_test_x)\n",
    "test_normalize = np.transpose(test_normalize)\n",
    "normalize_test_x = pd.DataFrame({\n",
    "    'Open Price': test_normalize[0],\n",
    "    'Close Price': test_normalize[1],\n",
    "    'High Price': test_normalize[2],\n",
    "    'Low Price': test_normalize[3],\n",
    "    'Tomorrow Open': test_normalize[4],\n",
    "    'S_10': test_normalize[5],\n",
    "    'Corr': test_normalize[6],\n",
    "    'Open-Close': test_normalize[7],\n",
    "    'Open-Open': test_normalize[8],\n",
    "})\n",
    "\n",
    "data_train_y = np.where(data_train_y == 0, -1, 1)\n",
    "data_test_y = np.where(data_test_y == 0, -1, 1)\n",
    "\n",
    "print(normalize_train_x.head())\n",
    "print(data_train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.6836007130124777\n",
      "\n",
      "testing accuracy:\n",
      "0.6952789699570815\n",
      "[-1  1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1 -1 -1  1  1  1  1  1  1  1 -1 -1\n",
      "  1 -1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1  1  1 -1  1 -1  1 -1  1 -1  1\n",
      "  1 -1  1  1  1  1  1 -1 -1  1  1 -1  1  1  1 -1  1 -1 -1  1  1  1  1 -1\n",
      "  1 -1  1 -1 -1  1  1 -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1  1  1 -1\n",
      " -1 -1  1  1  1 -1  1  1 -1  1 -1  1  1  1  1  1 -1  1  1  1 -1 -1 -1  1\n",
      " -1  1  1 -1  1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1 -1  1 -1  1  1 -1 -1\n",
      "  1  1  1  1 -1 -1 -1 -1  1 -1  1 -1 -1  1  1 -1  1 -1  1  1 -1 -1  1  1\n",
      " -1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1  1  1 -1  1  1 -1 -1  1 -1  1 -1  1\n",
      "  1 -1 -1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1  1 -1  1 -1  1  1 -1  1\n",
      " -1 -1 -1  1  1  1 -1 -1  1 -1 -1  1 -1  1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel='linear', C=3000, tol=1e-5)\n",
    "svc_model.fit(normalize_train_x, data_train_y)\n",
    "\n",
    "predict_train_y = svc_model.predict(normalize_train_x)\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(data_train_y, predict_train_y))\n",
    "\n",
    "svc_predict_test_y = svc_model.predict(normalize_test_x)\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(data_test_y, svc_predict_test_y))\n",
    "print(svc_predict_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.695036719122556, 0.6952789699570815, 0.6950423721854327, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(74, 37, 34, 88)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(data_test_y, svc_predict_test_y, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(data_test_y, svc_predict_test_y).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2244, 9)\n",
      "   Close Price      Corr  High Price  Low Price  Open Price  Open-Close  \\\n",
      "0    -0.855107 -1.025865   -0.850094  -0.855701   -0.851757   -1.067904   \n",
      "1    -0.866038 -1.065955   -0.852062  -0.865924   -0.854285    0.363856   \n",
      "2    -0.858859 -1.520172   -0.858036  -0.870271   -0.874822   -0.743042   \n",
      "3    -0.849637 -0.804563   -0.850930  -0.864326   -0.860570    0.072341   \n",
      "4    -0.849744 -0.440368   -0.839486  -0.850008   -0.852738   -0.092241   \n",
      "\n",
      "   Open-Open      S_10  Tomorrow Open  \n",
      "0  -0.017558 -0.844289      -0.857295  \n",
      "1  -0.291170 -0.844440      -0.877831  \n",
      "2  -1.424830 -0.844551      -0.863579  \n",
      "3   0.765235 -0.840887      -0.855747  \n",
      "4   0.361109 -0.839511      -0.862896  \n",
      "(2244, 2)\n",
      "   0  1\n",
      "0  1  0\n",
      "1  0  1\n",
      "2  0  1\n",
      "3  1  0\n",
      "4  0  1\n"
     ]
    }
   ],
   "source": [
    "left_col = pd.DataFrame(data=np.where(data_train_y == -1, 1, 0)[:])\n",
    "data_train_y = pd.DataFrame(data=np.where(data_train_y == -1, 0, 1)[:])\n",
    "data_train_y = pd.concat( [ left_col, data_train_y ], axis=1, ignore_index=True )\n",
    "\n",
    "left_col = pd.DataFrame(data=np.where(data_test_y == -1, 1, 0)[:])\n",
    "data_test_y = pd.DataFrame(data=np.where(data_test_y == -1, 0, 1)[:])\n",
    "data_test_y = pd.concat( [ left_col, data_test_y ], axis=1, ignore_index=True )\n",
    "\n",
    "print(normalize_train_x.shape)\n",
    "print(normalize_train_x.head())\n",
    "\n",
    "print(data_train_y.shape)\n",
    "print(data_train_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 416.1724548339844\n",
      "100 405.4530029296875\n",
      "200 404.59356689453125\n",
      "300 404.446533203125\n",
      "400 404.4302978515625\n",
      "500 404.3185119628906\n",
      "600 404.11614990234375\n",
      "700 403.8304443359375\n",
      "800 403.4712219238281\n",
      "900 403.052490234375\n",
      "1000 402.5887756347656\n",
      "1100 402.091552734375\n",
      "1200 401.5695495605469\n",
      "1300 401.02911376953125\n",
      "1400 400.47540283203125\n",
      "1500 399.9125061035156\n",
      "1600 399.34405517578125\n",
      "1700 398.7726135253906\n",
      "1800 398.20068359375\n",
      "1900 397.6304016113281\n",
      "2000 397.0627746582031\n",
      "2100 396.4991760253906\n",
      "2200 395.9407043457031\n",
      "2300 395.38775634765625\n",
      "2400 394.84100341796875\n",
      "2500 394.30072021484375\n",
      "2600 393.7673034667969\n",
      "2700 393.2408752441406\n",
      "2800 392.7214660644531\n",
      "2900 392.2092590332031\n",
      "3000 391.70404052734375\n",
      "3100 391.20611572265625\n",
      "3200 390.71527099609375\n",
      "3300 390.23138427734375\n",
      "3400 389.7544250488281\n",
      "3500 389.2845458984375\n",
      "3600 388.8213806152344\n",
      "3700 388.3648681640625\n",
      "3800 387.9148864746094\n",
      "3900 387.4715881347656\n",
      "4000 387.03466796875\n",
      "4100 386.6037902832031\n",
      "4200 386.1792907714844\n",
      "4300 385.76092529296875\n",
      "4400 385.3484802246094\n",
      "4500 384.9418640136719\n",
      "4600 384.541015625\n",
      "4700 384.1458740234375\n",
      "4800 383.7564392089844\n",
      "4900 383.37237548828125\n",
      "5000 382.9935607910156\n",
      "5100 382.6202392578125\n",
      "5200 382.2520751953125\n",
      "5300 381.8890380859375\n",
      "5400 381.53106689453125\n",
      "5500 381.1780090332031\n",
      "5600 380.829833984375\n",
      "5700 380.4864196777344\n",
      "5800 380.1477355957031\n",
      "5900 379.813720703125\n",
      "6000 379.484130859375\n",
      "6100 379.15911865234375\n",
      "6200 378.8385009765625\n",
      "6300 378.5220947265625\n",
      "6400 378.2100524902344\n",
      "6500 377.9023742675781\n",
      "6600 377.5985412597656\n",
      "6700 377.29901123046875\n",
      "6800 377.0032958984375\n",
      "6900 376.71173095703125\n",
      "7000 376.4238586425781\n",
      "7100 376.13983154296875\n",
      "7200 375.8596496582031\n",
      "7300 375.583251953125\n",
      "7400 375.3103942871094\n",
      "7500 375.04119873046875\n",
      "7600 374.7755126953125\n",
      "7700 374.5133361816406\n",
      "7800 374.2546081542969\n",
      "7900 373.999267578125\n",
      "8000 373.7471618652344\n",
      "8100 373.49847412109375\n",
      "8200 373.2529602050781\n",
      "8300 373.0107421875\n",
      "8400 372.7717590332031\n",
      "8500 372.5356750488281\n",
      "8600 372.30279541015625\n",
      "8700 372.0728759765625\n",
      "8800 371.8460388183594\n",
      "8900 371.62200927734375\n",
      "9000 371.4010314941406\n",
      "9100 371.1828918457031\n",
      "9200 370.9674072265625\n",
      "9300 370.75482177734375\n",
      "9400 370.5450134277344\n",
      "9500 370.33795166015625\n",
      "9600 370.1334228515625\n",
      "9700 369.93157958984375\n",
      "9800 369.73236083984375\n",
      "9900 369.5356750488281\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        acti_out = F.relu(h)\n",
    "        y_pred = self.linear2(h) #.clamp(0,1)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size\n",
    "N, D_in, H, D_out = 300, 9, 100, 2\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "for t in range(10000):\n",
    "    for batch_num in range(N, len(normalize_train_x), N):\n",
    "        \n",
    "        y_pred = model(torch.FloatTensor(normalize_train_x[batch_num-N:batch_num].values.tolist()))\n",
    "\n",
    "        loss = criterion(y_pred, torch.FloatTensor(data_train_y[batch_num-N:batch_num].values.tolist()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%100 == 0):\n",
    "        print(t, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.625222816399287\n",
      "\n",
      "testing accuracy:\n",
      "0.6137339055793991\n",
      "predicted testing prob:\n",
      "tensor([[ 9.3294e-01, -9.3287e-01],\n",
      "        [-2.6632e+00,  2.6634e+00],\n",
      "        [-6.9241e-01,  6.9212e-01],\n",
      "        [ 2.2451e-01, -2.2288e-01],\n",
      "        [ 2.0254e+00, -2.0245e+00],\n",
      "        [ 5.5696e+00, -5.5623e+00],\n",
      "        [ 1.9845e-01, -1.9040e-01],\n",
      "        [-1.9294e+00,  1.9334e+00],\n",
      "        [-2.6506e+00,  2.6534e+00],\n",
      "        [-4.0797e+00,  4.0795e+00],\n",
      "        [-7.1704e-01,  7.1970e-01],\n",
      "        [-6.0857e-01,  6.1023e-01],\n",
      "        [-4.1312e+00,  4.1361e+00],\n",
      "        [-2.3793e+00,  2.3811e+00],\n",
      "        [-1.8488e-01,  1.8753e-01],\n",
      "        [-2.0095e+00,  2.0129e+00],\n",
      "        [-2.1268e+00,  2.1307e+00],\n",
      "        [-3.0324e+00,  3.0334e+00],\n",
      "        [-3.4640e+00,  3.4661e+00],\n",
      "        [-2.3237e+00,  2.3252e+00],\n",
      "        [-2.8294e+00,  2.8307e+00],\n",
      "        [-1.3304e+00,  1.3317e+00],\n",
      "        [ 2.3458e+00, -2.3442e+00],\n",
      "        [-8.5531e-04,  4.5475e-03],\n",
      "        [-3.5986e+00,  3.6022e+00],\n",
      "        [-3.3192e-01,  3.3196e-01],\n",
      "        [-2.4352e+00,  2.4364e+00],\n",
      "        [-3.8987e+00,  3.8981e+00],\n",
      "        [-3.1507e+00,  3.1531e+00],\n",
      "        [-3.6471e+00,  3.6480e+00],\n",
      "        [-2.4190e+00,  2.4209e+00],\n",
      "        [-1.7963e+00,  1.7957e+00],\n",
      "        [-2.4981e+00,  2.4983e+00],\n",
      "        [ 8.8129e-01, -8.8187e-01],\n",
      "        [-1.0048e+00,  1.0036e+00],\n",
      "        [-6.2511e-01,  6.2439e-01],\n",
      "        [ 2.1127e+00, -2.1108e+00],\n",
      "        [-9.3596e-02,  9.4687e-02],\n",
      "        [-4.7134e+00,  4.7150e+00],\n",
      "        [-3.9184e+00,  3.9211e+00],\n",
      "        [ 6.7468e-01, -6.7189e-01],\n",
      "        [-1.0925e+00,  1.0938e+00],\n",
      "        [ 3.2640e-02, -2.7672e-02],\n",
      "        [-2.7329e+00,  2.7346e+00],\n",
      "        [ 2.8260e+00, -2.8262e+00],\n",
      "        [-3.4189e+00,  3.4265e+00],\n",
      "        [ 5.2464e-02, -5.1884e-02],\n",
      "        [-1.9346e+00,  1.9378e+00],\n",
      "        [-4.6129e+00,  4.6184e+00],\n",
      "        [-1.0120e+00,  1.0138e+00],\n",
      "        [-2.4215e+00,  2.4240e+00],\n",
      "        [-3.1241e+00,  3.1256e+00],\n",
      "        [-3.1131e+00,  3.1134e+00],\n",
      "        [-3.8154e+00,  3.8154e+00],\n",
      "        [-2.5241e+00,  2.5275e+00],\n",
      "        [-6.9392e-01,  6.9474e-01],\n",
      "        [-6.5546e-01,  6.5551e-01],\n",
      "        [-2.1253e+00,  2.1251e+00],\n",
      "        [-2.3176e+00,  2.3179e+00],\n",
      "        [-7.6834e-01,  7.6970e-01],\n",
      "        [-4.3089e+00,  4.3076e+00],\n",
      "        [-5.5983e+00,  5.6001e+00],\n",
      "        [-2.2664e+00,  2.2670e+00],\n",
      "        [-6.7937e-02,  6.9563e-02],\n",
      "        [-1.8865e+00,  1.8881e+00],\n",
      "        [-1.9848e-01,  1.9927e-01],\n",
      "        [-4.6844e-01,  4.6898e-01],\n",
      "        [-3.0275e+00,  3.0326e+00],\n",
      "        [-1.9122e+00,  1.9137e+00],\n",
      "        [-2.2254e+00,  2.2249e+00],\n",
      "        [-2.6461e+00,  2.6475e+00],\n",
      "        [-1.7549e+00,  1.7564e+00],\n",
      "        [-2.7712e+00,  2.7711e+00],\n",
      "        [ 1.8765e-01, -1.8663e-01],\n",
      "        [-1.5633e+00,  1.5619e+00],\n",
      "        [-9.2448e-01,  9.2530e-01],\n",
      "        [-6.4242e-01,  6.4354e-01],\n",
      "        [-3.2514e+00,  3.2509e+00],\n",
      "        [-2.8300e+00,  2.8304e+00],\n",
      "        [ 2.0019e-01, -2.0036e-01],\n",
      "        [-1.3837e+00,  1.3858e+00],\n",
      "        [-2.2368e+00,  2.2359e+00],\n",
      "        [-4.7963e-01,  4.7967e-01],\n",
      "        [-2.4719e+00,  2.4721e+00],\n",
      "        [-1.7706e+00,  1.7707e+00],\n",
      "        [-3.0147e+00,  3.0159e+00],\n",
      "        [-2.9000e+00,  2.9018e+00],\n",
      "        [-3.0315e+00,  3.0324e+00],\n",
      "        [-2.6852e+00,  2.6850e+00],\n",
      "        [-2.3508e+00,  2.3509e+00],\n",
      "        [-7.2489e-01,  7.2453e-01],\n",
      "        [-1.5067e+00,  1.5066e+00],\n",
      "        [-2.3820e+00,  2.3824e+00],\n",
      "        [-2.5039e+00,  2.5039e+00],\n",
      "        [-2.7035e+00,  2.7048e+00],\n",
      "        [-9.1893e-01,  9.2014e-01],\n",
      "        [-1.9648e-02,  1.9156e-02],\n",
      "        [ 1.4209e+00, -1.4205e+00],\n",
      "        [-3.0664e+00,  3.0669e+00],\n",
      "        [-3.1025e+00,  3.1037e+00],\n",
      "        [-2.3694e+00,  2.3696e+00],\n",
      "        [ 7.8584e-01, -7.8697e-01],\n",
      "        [-1.5113e+00,  1.5107e+00],\n",
      "        [-2.3270e+00,  2.3274e+00],\n",
      "        [-6.6638e-01,  6.6849e-01],\n",
      "        [-2.7878e+00,  2.7894e+00],\n",
      "        [ 1.9431e-01, -1.9343e-01],\n",
      "        [-2.5412e+00,  2.5436e+00],\n",
      "        [-3.4278e+00,  3.4283e+00],\n",
      "        [-2.4336e+00,  2.4336e+00],\n",
      "        [-3.7203e+00,  3.7231e+00],\n",
      "        [-2.8830e+00,  2.8832e+00],\n",
      "        [ 2.4083e-01, -2.4138e-01],\n",
      "        [-2.3095e+00,  2.3100e+00],\n",
      "        [-2.5895e+00,  2.5921e+00],\n",
      "        [-2.4887e+00,  2.4884e+00],\n",
      "        [ 4.7743e-01, -4.7778e-01],\n",
      "        [-1.8155e+00,  1.8188e+00],\n",
      "        [-1.4768e+00,  1.4762e+00],\n",
      "        [-2.4625e+00,  2.4623e+00],\n",
      "        [-1.2675e+00,  1.2676e+00],\n",
      "        [-4.8800e+00,  4.8796e+00],\n",
      "        [-2.2558e+00,  2.2568e+00],\n",
      "        [ 1.5505e+00, -1.5478e+00],\n",
      "        [-2.9711e+00,  2.9704e+00],\n",
      "        [-1.1983e+00,  1.1990e+00],\n",
      "        [-1.6256e+00,  1.6250e+00],\n",
      "        [-2.8191e+00,  2.8196e+00],\n",
      "        [-3.4480e-01,  3.4452e-01],\n",
      "        [-2.5484e+00,  2.5526e+00],\n",
      "        [-2.5442e+00,  2.5432e+00],\n",
      "        [-2.7910e+00,  2.7913e+00],\n",
      "        [-1.8844e+00,  1.8842e+00],\n",
      "        [-1.7647e+00,  1.7647e+00],\n",
      "        [ 3.1215e-01, -3.1179e-01],\n",
      "        [-1.8231e+00,  1.8225e+00],\n",
      "        [-2.5258e+00,  2.5273e+00],\n",
      "        [-7.3494e-02,  7.3001e-02],\n",
      "        [-3.2062e+00,  3.2056e+00],\n",
      "        [-9.7276e-01,  9.7245e-01],\n",
      "        [-2.1352e+00,  2.1348e+00],\n",
      "        [-2.6431e+00,  2.6417e+00],\n",
      "        [-8.9059e-01,  8.9155e-01],\n",
      "        [-1.5970e+00,  1.5974e+00],\n",
      "        [-2.6136e+00,  2.6147e+00],\n",
      "        [-3.5344e+00,  3.5347e+00],\n",
      "        [-3.2097e+00,  3.2099e+00],\n",
      "        [-2.6690e+00,  2.6683e+00],\n",
      "        [-1.8088e+00,  1.8106e+00],\n",
      "        [-1.6917e+00,  1.6932e+00],\n",
      "        [-1.0733e+00,  1.0739e+00],\n",
      "        [-1.2693e+00,  1.2685e+00],\n",
      "        [-1.5526e+00,  1.5522e+00],\n",
      "        [ 4.0292e-01, -4.0366e-01],\n",
      "        [-2.1713e+00,  2.1731e+00],\n",
      "        [-9.8069e-01,  9.7951e-01],\n",
      "        [-1.2567e+00,  1.2586e+00],\n",
      "        [-3.8245e+00,  3.8229e+00],\n",
      "        [-2.5099e+00,  2.5104e+00],\n",
      "        [-1.0704e+00,  1.0696e+00],\n",
      "        [-1.2138e+00,  1.2138e+00],\n",
      "        [-1.6286e+00,  1.6309e+00],\n",
      "        [-3.6371e+00,  3.6363e+00],\n",
      "        [-2.8080e+00,  2.8087e+00],\n",
      "        [ 1.7638e-01, -1.7595e-01],\n",
      "        [-1.8065e+00,  1.8073e+00],\n",
      "        [-2.3819e+00,  2.3810e+00],\n",
      "        [-2.8331e+00,  2.8358e+00],\n",
      "        [-1.5856e+00,  1.5872e+00],\n",
      "        [-3.5874e+00,  3.5876e+00],\n",
      "        [-1.6704e+00,  1.6713e+00],\n",
      "        [-2.7645e+00,  2.7659e+00],\n",
      "        [-8.7641e-01,  8.7624e-01],\n",
      "        [-8.3007e-01,  8.2988e-01],\n",
      "        [ 5.1791e-01, -5.1756e-01],\n",
      "        [-1.1535e+00,  1.1539e+00],\n",
      "        [ 2.7519e-01, -2.7318e-01],\n",
      "        [ 1.3096e+00, -1.3073e+00],\n",
      "        [-6.3196e+00,  6.3227e+00],\n",
      "        [-2.3160e+00,  2.3159e+00],\n",
      "        [-3.8592e+00,  3.8585e+00],\n",
      "        [-3.6243e+00,  3.6289e+00],\n",
      "        [-1.6971e+00,  1.6965e+00],\n",
      "        [-2.6659e+00,  2.6659e+00],\n",
      "        [-2.2663e+00,  2.2689e+00],\n",
      "        [ 3.1967e+00, -3.1955e+00],\n",
      "        [-5.9135e-01,  5.9466e-01],\n",
      "        [-3.4354e+00,  3.4394e+00],\n",
      "        [ 5.9365e+00, -5.9308e+00],\n",
      "        [-3.8612e+00,  3.8668e+00],\n",
      "        [-3.8916e-02,  4.2143e-02],\n",
      "        [-5.3880e+00,  5.3905e+00],\n",
      "        [-3.1649e+00,  3.1694e+00],\n",
      "        [-1.4870e+00,  1.4892e+00],\n",
      "        [-6.1018e-01,  6.1232e-01],\n",
      "        [-1.5764e+00,  1.5747e+00],\n",
      "        [-4.2922e+00,  4.2945e+00],\n",
      "        [-1.8460e+00,  1.8508e+00],\n",
      "        [ 3.1253e-01, -3.1246e-01],\n",
      "        [ 7.0467e-01, -7.0539e-01],\n",
      "        [-1.0741e+00,  1.0747e+00],\n",
      "        [-2.6819e+00,  2.6854e+00],\n",
      "        [-3.9274e-01,  3.9414e-01],\n",
      "        [ 8.4928e-01, -8.4529e-01],\n",
      "        [-4.6698e-01,  4.6841e-01],\n",
      "        [ 5.4956e+00, -5.4942e+00],\n",
      "        [-2.3499e+00,  2.3528e+00],\n",
      "        [-1.9151e-01,  1.9240e-01],\n",
      "        [-3.8710e+00,  3.8723e+00],\n",
      "        [-1.1860e+00,  1.1873e+00],\n",
      "        [-3.7682e+00,  3.7696e+00],\n",
      "        [-2.0763e+00,  2.0817e+00],\n",
      "        [-2.2892e+00,  2.2908e+00],\n",
      "        [-7.4380e+00,  7.4386e+00],\n",
      "        [-1.4750e+00,  1.4759e+00],\n",
      "        [-7.6219e+00,  7.6249e+00],\n",
      "        [ 2.4318e+00, -2.4422e+00],\n",
      "        [ 5.8273e-01, -5.7865e-01],\n",
      "        [-1.4059e-01,  1.4450e-01],\n",
      "        [-4.5310e+00,  4.5327e+00],\n",
      "        [-5.3989e+00,  5.3992e+00],\n",
      "        [-2.5318e+00,  2.5349e+00],\n",
      "        [ 1.7118e+00, -1.7112e+00],\n",
      "        [ 7.6299e-01, -7.6249e-01],\n",
      "        [-2.0792e+00,  2.0816e+00],\n",
      "        [-9.6274e-01,  9.6362e-01],\n",
      "        [ 9.3574e-01, -9.3020e-01],\n",
      "        [-2.0080e+00,  2.0101e+00],\n",
      "        [ 1.8063e+00, -1.8036e+00],\n",
      "        [-1.4902e+00,  1.4929e+00],\n",
      "        [ 6.1257e-01, -6.0295e-01],\n",
      "        [-4.1476e+00,  4.1504e+00],\n",
      "        [-4.0787e+00,  4.0819e+00]], grad_fn=<AddmmBackward>)\n",
      "predicted testing labels:\n",
      "[1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 1 0 0 1 0 1 0 1 0 0]\n",
      "precision, recall, fbeta-score:\n",
      "(0.6714440817799076, 0.6137339055793991, 0.5650350410170044, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(113, 9, 81, 30)\n"
     ]
    }
   ],
   "source": [
    "nn_predict_train_y = model.forward( torch.FloatTensor(normalize_train_x.values.tolist()))\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 1, 0)\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(data_train_y[0], result_train))\n",
    "\n",
    "nn_predict_y = model.forward( torch.FloatTensor(normalize_test_x.values.tolist()))\n",
    "result = np.where(nn_predict_y[:, 0] > nn_predict_y[:, 1], 1, 0)\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(data_test_y[0], result))\n",
    "\n",
    "print('predicted testing prob:')\n",
    "print(nn_predict_y)\n",
    "print('predicted testing labels:')\n",
    "print(result)\n",
    "\n",
    "\n",
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(data_test_y[0], result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(data_test_y[0], result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
