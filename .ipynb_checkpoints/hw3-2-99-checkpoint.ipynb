{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction\n",
    "\n",
    "包含的檔案：\n",
    "- hw3.ipynb\n",
    "- README.md\n",
    "\n",
    "欄位定義：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 4)\n",
      "   Open Price  Close Price  High Price  Low Price\n",
      "0      902.99       931.80      934.73     899.35\n",
      "1      929.17       927.45      936.63     919.53\n",
      "2      931.17       934.70      943.85     927.28\n",
      "3      927.45       906.65      927.45     902.37\n",
      "4      905.73       909.73      910.00     896.81\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "train_df.drop(columns=['Date', 'Volume'], inplace=True) # , 'Volume', 'High Price', 'Low Price'\n",
    "test_df.drop(columns=['Date', 'Volume'], inplace=True) # , 'Volume', 'High Price', 'Low Price'\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price  Movement\n",
      "0      902.99       931.80      934.73     899.35         0\n",
      "1      929.17       927.45      936.63     919.53         0\n",
      "2      931.17       934.70      943.85     927.28         1\n",
      "3      927.45       906.65      927.45     902.37         0\n",
      "4      905.73       909.73      910.00     896.81         1\n"
     ]
    }
   ],
   "source": [
    "# Add a column `Movement` as the target\n",
    "\n",
    "train_df['Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "#train_df['Movement'] = np.where(train_df['Close Price'].shift(-1) - train_df['Close Price'] >= 0, 1, 0)\n",
    "#test_df['Movement'] = np.where(test_df['Close Price'].shift(-1) - test_df['Close Price'] >= 0, 1, 0)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Open Price  Close Price  High Price  Low Price  Movement     S_10  \\\n",
      "18      868.89       845.14      868.89     844.15         0  840.028   \n",
      "19      845.69       825.88      851.66     821.67         0  838.242   \n",
      "20      823.09       825.44      830.78     812.87         0  835.774   \n",
      "21      825.69       838.51      842.60     821.98         1  839.103   \n",
      "22      837.77       832.23      851.85     829.18         0  838.302   \n",
      "\n",
      "        Corr  Open-Close  Open-Open  \n",
      "18 -0.237592       -5.20      23.16  \n",
      "19 -0.264066        0.55     -23.20  \n",
      "20 -0.501164       -2.79     -22.60  \n",
      "21 -0.121338        0.25       2.60  \n",
      "22 -0.187328       -0.74      12.08  \n",
      "    Open Price  Close Price  High Price  Low Price  Movement      S_10  \\\n",
      "18     2867.23      2853.53     2870.62    2851.48         0  2826.260   \n",
      "19     2832.74      2822.43     2837.75    2818.27         0  2830.861   \n",
      "20     2832.41      2823.81     2839.26    2813.04         1  2832.986   \n",
      "21     2816.45      2821.98     2835.96    2812.70         0  2835.381   \n",
      "22     2808.92      2762.13     2808.92    2759.97         0  2830.564   \n",
      "\n",
      "        Corr  Open-Close  Open-Open  \n",
      "18  0.945994       -5.64      19.75  \n",
      "19  0.745889      -20.79     -34.49  \n",
      "20  0.540062        9.98      -0.33  \n",
      "21  0.185381       -7.36     -15.96  \n",
      "22 -0.300583      -13.06      -7.53  \n"
     ]
    }
   ],
   "source": [
    "# New Features\n",
    "\n",
    "train_df['S_10'] = train_df['Close Price'].rolling(window=10).mean()\n",
    "train_df['Corr'] = train_df['Close Price'].rolling(window=10).corr(train_df['S_10'])\n",
    "train_df['Open-Close'] = train_df['Open Price'] - train_df['Close Price'].shift(1)\n",
    "train_df['Open-Open'] = train_df['Open Price'] - train_df['Open Price'].shift(1)\n",
    "#train_df['Close Price'] = train_df['Close Price'].shift(1)\n",
    "train_df = train_df.dropna()\n",
    "new_train_df = train_df.iloc[:,:9]\n",
    "\n",
    "print(new_train_df.head())\n",
    "\n",
    "test_df['S_10'] = test_df['Close Price'].rolling(window=10).mean()\n",
    "test_df['Corr'] = test_df['Close Price'].rolling(window=10).corr(test_df['S_10'])\n",
    "test_df['Open-Close'] = test_df['Open Price'] - test_df['Close Price'].shift(1)\n",
    "test_df['Open-Open'] = test_df['Open Price'] - test_df['Open Price'].shift(1)\n",
    "#test_df['Close Price'] = test_df['Close Price'].shift(1)\n",
    "test_df = test_df.dropna()\n",
    "new_test_df = test_df.iloc[:,:9]\n",
    "\n",
    "print(new_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2246, 8)\n",
      "    Open Price  Close Price  High Price  Low Price     S_10      Corr  \\\n",
      "18      868.89       845.14      868.89     844.15  840.028 -0.237592   \n",
      "19      845.69       825.88      851.66     821.67  838.242 -0.264066   \n",
      "20      823.09       825.44      830.78     812.87  835.774 -0.501164   \n",
      "21      825.69       838.51      842.60     821.98  839.103 -0.121338   \n",
      "22      837.77       832.23      851.85     829.18  838.302 -0.187328   \n",
      "\n",
      "    Open-Close  Open-Open  \n",
      "18       -5.20      23.16  \n",
      "19        0.55     -23.20  \n",
      "20       -2.79     -22.60  \n",
      "21        0.25       2.60  \n",
      "22       -0.74      12.08  \n",
      "(2246,)\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    1\n",
      "22    0\n",
      "Name: Movement, dtype: int64\n",
      "-----\n",
      "(234, 8)\n",
      "    Open Price  Close Price  High Price  Low Price      S_10      Corr  \\\n",
      "18     2867.23      2853.53     2870.62    2851.48  2826.260  0.945994   \n",
      "19     2832.74      2822.43     2837.75    2818.27  2830.861  0.745889   \n",
      "20     2832.41      2823.81     2839.26    2813.04  2832.986  0.540062   \n",
      "21     2816.45      2821.98     2835.96    2812.70  2835.381  0.185381   \n",
      "22     2808.92      2762.13     2808.92    2759.97  2830.564 -0.300583   \n",
      "\n",
      "    Open-Close  Open-Open  \n",
      "18       -5.64      19.75  \n",
      "19      -20.79     -34.49  \n",
      "20        9.98      -0.33  \n",
      "21       -7.36     -15.96  \n",
      "22      -13.06      -7.53  \n",
      "(234,)\n",
      "18    0\n",
      "19    0\n",
      "20    1\n",
      "21    0\n",
      "22    0\n",
      "Name: Movement, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# New ways to preprocess\n",
    "\n",
    "data_train_x = new_train_df.drop(columns=['Movement'])\n",
    "data_train_y = new_train_df['Movement']\n",
    "\n",
    "data_test_x = new_test_df.drop(columns=['Movement'])\n",
    "data_test_y = new_test_df['Movement']\n",
    "\n",
    "print(data_train_x.shape)\n",
    "print(data_train_x.head())\n",
    "print(data_train_y.shape)\n",
    "print(data_train_y.head())\n",
    "print('-----')\n",
    "print(data_test_x.shape)\n",
    "print(data_test_x.head())\n",
    "print(data_test_y.shape)\n",
    "print(data_test_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968833481745325\n",
      "0.9914529914529915\n",
      "[[1.00000000e+000 3.89564026e-023]\n",
      " [1.00000000e+000 1.56532382e-036]\n",
      " [2.64026914e-002 9.73597309e-001]\n",
      " [9.88522132e-001 1.14778683e-002]\n",
      " [1.00000000e+000 7.07848933e-070]\n",
      " [1.00000000e+000 1.84801206e-131]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.71182157e-015]\n",
      " [1.00000000e+000 5.45643702e-117]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.82424942e-009 9.99999998e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.16489504e-001 8.83510496e-001]\n",
      " [1.00000000e+000 2.02927636e-019]\n",
      " [1.00000000e+000 1.58671169e-018]\n",
      " [2.77438962e-003 9.97225610e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 6.18420411e-042]\n",
      " [1.00000000e+000 2.08220767e-036]\n",
      " [1.00000000e+000 1.17045271e-042]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [3.77424225e-009 9.99999996e-001]\n",
      " [9.33482266e-001 6.65177335e-002]\n",
      " [7.99360578e-015 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99951511e-001 4.84888883e-005]\n",
      " [1.00000000e+000 1.23792785e-021]\n",
      " [1.00000000e+000 2.12309970e-019]\n",
      " [9.97619892e-001 2.38010810e-003]\n",
      " [4.22512600e-006 9.99995775e-001]\n",
      " [1.00000000e+000 9.05363687e-046]\n",
      " [2.08465599e-005 9.99979153e-001]\n",
      " [9.99998195e-001 1.80495352e-006]\n",
      " [1.00000000e+000 1.97172553e-079]\n",
      " [1.00000000e+000 9.41751928e-065]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.31862146e-053]\n",
      " [9.99999997e-001 3.04092844e-009]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.46302909e-068]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 2.96092029e-068]\n",
      " [1.73055570e-010 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.01450165e-017]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99999999e-001 5.44429929e-010]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [3.70946122e-003 9.96290539e-001]\n",
      " [1.00000000e+000 1.09526539e-018]\n",
      " [1.00000000e+000 2.12788355e-027]\n",
      " [4.08816288e-001 5.91183712e-001]\n",
      " [1.00000000e+000 3.38766691e-042]\n",
      " [1.58092578e-006 9.99998419e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [4.23893201e-004 9.99576107e-001]\n",
      " [1.00000000e+000 2.54850030e-026]\n",
      " [9.99568017e-009 9.99999990e-001]\n",
      " [1.00000000e+000 7.67281639e-023]\n",
      " [9.99999614e-001 3.85625178e-007]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [2.14335216e-011 1.00000000e+000]\n",
      " [8.57223157e-001 1.42776843e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [5.48308171e-006 9.99994517e-001]\n",
      " [2.94427265e-003 9.97055727e-001]\n",
      " [1.00000000e+000 2.59199897e-022]\n",
      " [1.79412041e-013 1.00000000e+000]\n",
      " [9.97565704e-001 2.43429555e-003]\n",
      " [9.99999994e-001 5.71868041e-009]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 9.01597892e-011]\n",
      " [2.97648572e-011 1.00000000e+000]\n",
      " [9.99999358e-001 6.42285063e-007]\n",
      " [9.99999957e-001 4.29782004e-008]\n",
      " [1.00000000e+000 7.24642006e-037]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 2.49197619e-022]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [7.54951657e-015 1.00000000e+000]\n",
      " [5.78493014e-003 9.94215070e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.95421030e-001 4.57897023e-003]\n",
      " [8.00306488e-011 1.00000000e+000]\n",
      " [4.47305213e-004 9.99552695e-001]\n",
      " [2.83386044e-006 9.99997166e-001]\n",
      " [1.00000000e+000 7.81389620e-014]\n",
      " [1.43814942e-008 9.99999986e-001]\n",
      " [9.99142969e-001 8.57031242e-004]\n",
      " [9.99999672e-001 3.28487734e-007]\n",
      " [1.00000000e+000 3.62673611e-013]\n",
      " [3.77780518e-006 9.99996222e-001]\n",
      " [1.00000000e+000 3.76570007e-021]\n",
      " [1.97014284e-006 9.99998030e-001]\n",
      " [1.00000000e+000 3.16139055e-044]\n",
      " [8.52878859e-008 9.99999915e-001]\n",
      " [1.00000000e+000 9.07937785e-028]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [3.54273814e-003 9.96457262e-001]\n",
      " [6.34863273e-011 1.00000000e+000]\n",
      " [1.00000000e+000 2.58484286e-016]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.32387434e-011 1.00000000e+000]\n",
      " [1.00000000e+000 8.21375220e-024]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [3.40942365e-004 9.99659058e-001]\n",
      " [9.99622958e-001 3.77041948e-004]\n",
      " [8.17124146e-014 1.00000000e+000]\n",
      " [8.09411643e-008 9.99999919e-001]\n",
      " [1.00000000e+000 1.56850078e-013]\n",
      " [9.99154768e-001 8.45231656e-004]\n",
      " [7.39852543e-007 9.99999260e-001]\n",
      " [4.44089210e-016 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.39730689e-010]\n",
      " [1.00000000e+000 2.23865169e-022]\n",
      " [1.00000000e+000 1.37736511e-019]\n",
      " [2.22044605e-016 1.00000000e+000]\n",
      " [9.99589252e-001 4.10748127e-004]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [4.44089210e-016 1.00000000e+000]\n",
      " [1.94200211e-012 1.00000000e+000]\n",
      " [6.26665164e-010 9.99999999e-001]\n",
      " [8.84786815e-001 1.15213185e-001]\n",
      " [9.99984684e-001 1.53157394e-005]\n",
      " [1.00000000e+000 5.06983861e-024]\n",
      " [1.00000000e+000 6.91877084e-014]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.93817918e-025]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.35984623e-012 1.00000000e+000]\n",
      " [1.17078137e-008 9.99999988e-001]\n",
      " [2.10103828e-007 9.99999790e-001]\n",
      " [9.55846032e-001 4.41539677e-002]\n",
      " [9.99997544e-001 2.45621329e-006]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.44622373e-001 8.55377627e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.19144654e-015]\n",
      " [2.39383169e-001 7.60616831e-001]\n",
      " [9.99996087e-001 3.91326519e-006]\n",
      " [9.99999999e-001 5.88725269e-010]\n",
      " [1.00000000e+000 7.41897549e-013]\n",
      " [9.99999937e-001 6.30626049e-008]\n",
      " [6.77134086e-007 9.99999323e-001]\n",
      " [2.30926389e-013 1.00000000e+000]\n",
      " [6.24956359e-002 9.37504364e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.39905640e-001 8.60094360e-001]\n",
      " [1.00000000e+000 1.16553904e-019]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [8.45580870e-005 9.99915442e-001]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.62815518e-001 3.71844823e-002]\n",
      " [1.00000000e+000 1.36933503e-012]\n",
      " [9.99965662e-001 3.43380942e-005]\n",
      " [1.00000000e+000 6.76977185e-012]\n",
      " [5.79664095e-010 9.99999999e-001]\n",
      " [4.49024776e-001 5.50975224e-001]\n",
      " [7.17204074e-013 1.00000000e+000]\n",
      " [9.61249788e-001 3.87502124e-002]\n",
      " [6.30098946e-003 9.93699011e-001]\n",
      " [1.00000000e+000 2.59297694e-028]\n",
      " [1.00000000e+000 3.17673389e-019]\n",
      " [8.91805372e-001 1.08194628e-001]\n",
      " [9.99965976e-001 3.40244989e-005]\n",
      " [1.00000000e+000 3.43133258e-110]\n",
      " [1.00000000e+000 1.30089176e-066]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 4.16683535e-019]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [7.01090883e-001 2.98909117e-001]\n",
      " [1.00000000e+000 2.37330391e-047]\n",
      " [9.39210018e-001 6.07899816e-002]\n",
      " [1.00000000e+000 1.65682880e-014]\n",
      " [1.00000000e+000 2.00018114e-017]\n",
      " [1.00000000e+000 1.54766578e-098]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 7.75634766e-054]\n",
      " [1.00000000e+000 1.35718942e-020]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 7.11328908e-021]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99999996e-001 3.77722036e-009]\n",
      " [1.00000000e+000 9.91387847e-031]\n",
      " [1.00000000e+000 2.42785012e-064]\n",
      " [9.99983547e-001 1.64531449e-005]\n",
      " [1.00000000e+000 1.12463707e-024]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [2.87696110e-008 9.99999971e-001]\n",
      " [1.00000000e+000 2.41252759e-053]\n",
      " [1.00000000e+000 1.11594902e-056]\n",
      " [3.78731935e-010 1.00000000e+000]\n",
      " [1.00000000e+000 2.85420404e-020]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [2.19113616e-011 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99999880e-001 1.20124165e-007]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 6.87783584e-106]\n",
      " [9.80098505e-001 1.99014952e-002]\n",
      " [9.99871309e-001 1.28690950e-004]\n",
      " [1.00000000e+000 2.42635129e-073]\n",
      " [1.09746126e-006 9.99998903e-001]\n",
      " [9.31549242e-001 6.84507576e-002]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [7.71538834e-001 2.28461166e-001]\n",
      " [1.00000000e+000 6.86857466e-059]\n",
      " [1.00000000e+000 7.55144187e-063]\n",
      " [2.19867405e-001 7.80132595e-001]\n",
      " [1.00000000e+000 1.09214218e-045]\n",
      " [1.00000000e+000 8.82062733e-046]\n",
      " [1.00000000e+000 5.09715354e-059]\n",
      " [1.00000000e+000 8.38820401e-076]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [9.99655280e-001 3.44720278e-004]\n",
      " [0.00000000e+000 1.00000000e+000]]\n",
      "[0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1\n",
      " 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 1\n",
      " 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "#lr_model = SGDClassifier(loss='log',  max_iter=800)\n",
    "lr_model.fit(data_train_x, data_train_y)\n",
    "\n",
    "predict_train_y = lr_model.predict(data_train_x)\n",
    "print(accuracy_score(data_train_y, predict_train_y))\n",
    "\n",
    "predict_test_y = lr_model.predict(data_test_x)\n",
    "print(accuracy_score(data_test_y, predict_test_y))\n",
    "\n",
    "print(lr_model.predict_proba(data_test_x))\n",
    "print(predict_test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Close Price      Corr  High Price  Low Price  Open Price  Open-Close  \\\n",
      "0    -0.984916 -1.073559   -0.963934  -0.977600   -0.952521   -2.492823   \n",
      "1    -1.008335 -1.110115   -0.984901  -1.004967   -0.980705    0.258373   \n",
      "2    -1.008870 -1.437500   -1.010310  -1.015680   -1.008161   -1.339713   \n",
      "3    -0.992978 -0.913035   -0.995926  -1.004590   -1.005002    0.114833   \n",
      "4    -1.000614 -1.004154   -0.984670  -0.995824   -0.990327   -0.358852   \n",
      "\n",
      "   Open-Open      S_10  \n",
      "0   1.572616 -0.980213  \n",
      "1  -1.777095 -0.982372  \n",
      "2  -1.733743 -0.985357  \n",
      "3   0.087066 -0.981331  \n",
      "4   0.772038 -0.982300  \n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(data_train_x) #scaler.fit(train_df.append(test_df, ignore_index=True))\n",
    "\n",
    "train_normalize = scaler.transform(data_train_x)\n",
    "train_normalize = np.transpose(train_normalize)\n",
    "\n",
    "normalize_train_x = pd.DataFrame({\n",
    "    'Open Price': train_normalize[0],\n",
    "    'Close Price': train_normalize[1],\n",
    "    'High Price': train_normalize[2],\n",
    "    'Low Price': train_normalize[3],\n",
    "    'S_10': train_normalize[4],\n",
    "    'Corr': train_normalize[5],\n",
    "    'Open-Close': train_normalize[6],\n",
    "    'Open-Open': train_normalize[7],\n",
    "})\n",
    "\n",
    "test_normalize = scaler.transform(data_test_x)\n",
    "test_normalize = np.transpose(test_normalize)\n",
    "normalize_test_x = pd.DataFrame({\n",
    "    'Open Price': test_normalize[0],\n",
    "    'Close Price': test_normalize[1],\n",
    "    'High Price': test_normalize[2],\n",
    "    'Low Price': test_normalize[3],\n",
    "    'S_10': test_normalize[4],\n",
    "    'Corr': test_normalize[5],\n",
    "    'Open-Close': test_normalize[6],\n",
    "    'Open-Open': test_normalize[7],\n",
    "})\n",
    "\n",
    "print(normalize_train_x.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9594835262689225\n",
      "0.9444444444444444\n",
      "[-1 -1  1 -1 -1 -1  1 -1 -1  1  1 -1  1  1 -1 -1 -1  1  1  1 -1 -1 -1  1\n",
      "  1  1 -1  1  1 -1 -1 -1  1  1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1  1  1 -1\n",
      "  1  1 -1  1 -1  1  1  1 -1 -1  1 -1  1  1  1 -1  1 -1 -1  1  1 -1  1  1\n",
      "  1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1  1 -1  1  1  1  1 -1  1  1  1 -1  1\n",
      " -1 -1 -1  1 -1  1 -1  1 -1  1  1 -1 -1  1  1  1  1 -1  1  1 -1  1  1 -1\n",
      " -1  1  1  1 -1 -1 -1  1 -1  1  1  1  1 -1 -1 -1 -1  1 -1  1  1  1  1 -1\n",
      " -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1 -1  1  1  1  1 -1 -1 -1\n",
      "  1 -1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1 -1  1\n",
      "  1  1 -1  1  1  1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1  1  1  1 -1  1  1 -1\n",
      "  1 -1 -1 -1  1  1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "data_train_y = np.where(data_train_y == 0, -1, 1)\n",
    "data_test_y = np.where(data_test_y == 0, -1, 1)\n",
    "\n",
    "svc_model = SVC(kernel='linear', C=100, tol=1e-5) # kernel='rbf', C=100, tol=1e-5\n",
    "svc_model.fit(normalize_train_x, data_train_y)\n",
    "\n",
    "predict_train_y = svc_model.predict(normalize_train_x)\n",
    "print(accuracy_score(data_train_y, predict_train_y))\n",
    "\n",
    "predict_test_y = svc_model.predict(normalize_test_x)\n",
    "print(accuracy_score(data_test_y, predict_test_y))\n",
    "print(predict_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 137.91221618652344\n",
      "50 136.73919677734375\n",
      "100 136.73912048339844\n",
      "150 136.73812866210938\n",
      "200 136.73716735839844\n",
      "250 136.73619079589844\n",
      "300 136.73524475097656\n",
      "350 136.73428344726562\n",
      "400 136.73336791992188\n",
      "450 136.732421875\n",
      "500 136.7315216064453\n",
      "550 136.73062133789062\n",
      "600 136.72972106933594\n",
      "650 136.72886657714844\n",
      "700 136.7279815673828\n",
      "750 136.7270965576172\n",
      "800 136.7262420654297\n",
      "850 136.7253875732422\n",
      "900 136.72454833984375\n",
      "950 136.72372436523438\n",
      "1000 136.72286987304688\n",
      "1050 136.7220458984375\n",
      "1100 136.7212371826172\n",
      "1150 136.7204132080078\n",
      "1200 136.7196044921875\n",
      "1250 136.7188262939453\n",
      "1300 136.71807861328125\n",
      "1350 136.71728515625\n",
      "1400 136.71652221679688\n",
      "1450 136.71575927734375\n",
      "1500 136.71499633789062\n",
      "1550 136.71424865722656\n",
      "1600 136.71351623535156\n",
      "1650 136.71278381347656\n",
      "1700 136.7120361328125\n",
      "1750 136.71131896972656\n",
      "1800 136.7106170654297\n",
      "1850 136.70989990234375\n",
      "1900 136.70916748046875\n",
      "1950 136.70848083496094\n",
      "2000 136.70779418945312\n",
      "2050 136.70712280273438\n",
      "2100 136.70643615722656\n",
      "2150 136.70574951171875\n",
      "2200 136.705078125\n",
      "2250 136.7043914794922\n",
      "2300 136.70372009277344\n",
      "2350 136.7030792236328\n",
      "2400 136.70245361328125\n",
      "2450 136.70181274414062\n",
      "2500 136.70115661621094\n",
      "2550 136.7005157470703\n",
      "2600 136.69989013671875\n",
      "2650 136.69927978515625\n",
      "2700 136.6986083984375\n",
      "2750 136.69802856445312\n",
      "2800 136.6973876953125\n",
      "2850 136.69676208496094\n",
      "2900 136.69619750976562\n",
      "2950 136.69557189941406\n",
      "tensor([[-0.2091,  0.2102],\n",
      "        [-0.2350,  0.2389],\n",
      "        [-0.0398,  0.0367],\n",
      "        [-0.1479,  0.1497],\n",
      "        [-0.2277,  0.2244],\n",
      "        [-0.2141,  0.2089],\n",
      "        [-0.2363,  0.2416],\n",
      "        [-0.4100,  0.4037],\n",
      "        [-0.1869,  0.1729],\n",
      "        [ 0.1324, -0.1432],\n",
      "        [-0.1209,  0.1135],\n",
      "        [-0.2806,  0.2796],\n",
      "        [-0.2564,  0.2599],\n",
      "        [-0.1093,  0.1057],\n",
      "        [-0.1192,  0.1246],\n",
      "        [-0.1386,  0.1427],\n",
      "        [-0.0142,  0.0167],\n",
      "        [ 0.0478, -0.0464],\n",
      "        [ 0.0292, -0.0278],\n",
      "        [-0.0830,  0.0836],\n",
      "        [-0.1414,  0.1411],\n",
      "        [ 0.0290, -0.0309],\n",
      "        [-0.0320,  0.0291],\n",
      "        [-0.1820,  0.1857],\n",
      "        [-0.2730,  0.2747],\n",
      "        [-0.1496,  0.1447],\n",
      "        [-0.2264,  0.2302],\n",
      "        [-0.0948,  0.0929],\n",
      "        [-0.0076,  0.0082],\n",
      "        [-0.1462,  0.1467],\n",
      "        [-0.0231,  0.0226],\n",
      "        [ 0.0046, -0.0057],\n",
      "        [-0.0354,  0.0354],\n",
      "        [-0.0831,  0.0833],\n",
      "        [-0.2039,  0.2013],\n",
      "        [-0.0400,  0.0390],\n",
      "        [-0.1231,  0.1230],\n",
      "        [-0.2755,  0.2730],\n",
      "        [-0.0667,  0.0593],\n",
      "        [ 0.1499, -0.1572],\n",
      "        [-0.2164,  0.2055],\n",
      "        [-0.0678,  0.0665],\n",
      "        [-0.0898,  0.0882],\n",
      "        [-0.2932,  0.2859],\n",
      "        [ 0.0169, -0.0190],\n",
      "        [-0.4011,  0.4080],\n",
      "        [-0.1531,  0.1501],\n",
      "        [-0.2366,  0.2370],\n",
      "        [ 0.0627, -0.0617],\n",
      "        [ 0.0841, -0.0864],\n",
      "        [-0.2189,  0.2227],\n",
      "        [-0.0100,  0.0105],\n",
      "        [-0.0242,  0.0211],\n",
      "        [ 0.0292, -0.0289],\n",
      "        [-0.0311,  0.0314],\n",
      "        [-0.1169,  0.1183],\n",
      "        [-0.1692,  0.1713],\n",
      "        [-0.1199,  0.1188],\n",
      "        [-0.0514,  0.0501],\n",
      "        [-0.0588,  0.0518],\n",
      "        [-0.0303,  0.0288],\n",
      "        [-0.0470,  0.0445],\n",
      "        [-0.0812,  0.0775],\n",
      "        [-0.0463,  0.0440],\n",
      "        [-0.0766,  0.0767],\n",
      "        [-0.1571,  0.1549],\n",
      "        [-0.1700,  0.1685],\n",
      "        [-0.1948,  0.1980],\n",
      "        [-0.1628,  0.1614],\n",
      "        [-0.1330,  0.1332],\n",
      "        [-0.0653,  0.0664],\n",
      "        [-0.0889,  0.0903],\n",
      "        [-0.1386,  0.1410],\n",
      "        [-0.0769,  0.0784],\n",
      "        [-0.1902,  0.1929],\n",
      "        [-0.0984,  0.1004],\n",
      "        [-0.1683,  0.1693],\n",
      "        [-0.1501,  0.1503],\n",
      "        [-0.0257,  0.0247],\n",
      "        [-0.0988,  0.0971],\n",
      "        [-0.1555,  0.1587],\n",
      "        [-0.1852,  0.1830],\n",
      "        [-0.1453,  0.1456],\n",
      "        [-0.2391,  0.2394],\n",
      "        [-0.0028,  0.0017],\n",
      "        [-0.1947,  0.1926],\n",
      "        [ 0.0082, -0.0092],\n",
      "        [-0.0998,  0.0989],\n",
      "        [-0.1245,  0.1245],\n",
      "        [-0.0917,  0.0930],\n",
      "        [-0.1443,  0.1442],\n",
      "        [-0.1364,  0.1397],\n",
      "        [-0.1353,  0.1371],\n",
      "        [-0.0995,  0.0999],\n",
      "        [-0.1160,  0.1162],\n",
      "        [-0.0474,  0.0468],\n",
      "        [-0.1633,  0.1633],\n",
      "        [-0.2298,  0.2318],\n",
      "        [-0.2838,  0.2866],\n",
      "        [-0.0826,  0.0800],\n",
      "        [-0.0844,  0.0815],\n",
      "        [ 0.0190, -0.0216],\n",
      "        [-0.2005,  0.1978],\n",
      "        [-0.0564,  0.0543],\n",
      "        [-0.1276,  0.1237],\n",
      "        [-0.1058,  0.1057],\n",
      "        [-0.1185,  0.1151],\n",
      "        [-0.2194,  0.2219],\n",
      "        [-0.1495,  0.1455],\n",
      "        [-0.0073,  0.0060],\n",
      "        [-0.1173,  0.1188],\n",
      "        [-0.0563,  0.0571],\n",
      "        [-0.0662,  0.0680],\n",
      "        [-0.1775,  0.1820],\n",
      "        [-0.0198,  0.0209],\n",
      "        [-0.1481,  0.1497],\n",
      "        [-0.1208,  0.1217],\n",
      "        [-0.1686,  0.1731],\n",
      "        [-0.1555,  0.1554],\n",
      "        [-0.1780,  0.1791],\n",
      "        [-0.1165,  0.1168],\n",
      "        [-0.1415,  0.1422],\n",
      "        [-0.0506,  0.0480],\n",
      "        [-0.1302,  0.1334],\n",
      "        [-0.2482,  0.2509],\n",
      "        [-0.0947,  0.0920],\n",
      "        [-0.0672,  0.0665],\n",
      "        [-0.0342,  0.0339],\n",
      "        [-0.1040,  0.1017],\n",
      "        [-0.1870,  0.1907],\n",
      "        [-0.1556,  0.1548],\n",
      "        [-0.1298,  0.1306],\n",
      "        [-0.0910,  0.0912],\n",
      "        [-0.1323,  0.1338],\n",
      "        [-0.1257,  0.1268],\n",
      "        [-0.2159,  0.2179],\n",
      "        [-0.0983,  0.0970],\n",
      "        [-0.0510,  0.0505],\n",
      "        [-0.2243,  0.2232],\n",
      "        [ 0.0176, -0.0190],\n",
      "        [-0.1246,  0.1254],\n",
      "        [-0.0908,  0.0901],\n",
      "        [-0.0696,  0.0704],\n",
      "        [-0.1240,  0.1251],\n",
      "        [-0.1313,  0.1323],\n",
      "        [-0.0774,  0.0781],\n",
      "        [-0.0735,  0.0734],\n",
      "        [-0.1047,  0.1047],\n",
      "        [-0.0793,  0.0814],\n",
      "        [-0.1790,  0.1801],\n",
      "        [-0.1193,  0.1209],\n",
      "        [-0.1625,  0.1628],\n",
      "        [-0.1610,  0.1608],\n",
      "        [-0.1174,  0.1155],\n",
      "        [-0.1495,  0.1513],\n",
      "        [-0.0341,  0.0311],\n",
      "        [-0.1125,  0.1139],\n",
      "        [-0.1107,  0.1094],\n",
      "        [-0.0199,  0.0194],\n",
      "        [-0.0754,  0.0747],\n",
      "        [-0.0807,  0.0803],\n",
      "        [-0.0236,  0.0255],\n",
      "        [-0.0894,  0.0893],\n",
      "        [-0.0186,  0.0185],\n",
      "        [-0.0882,  0.0877],\n",
      "        [-0.1506,  0.1525],\n",
      "        [-0.0950,  0.0945],\n",
      "        [-0.0886,  0.0886],\n",
      "        [-0.0478,  0.0478],\n",
      "        [-0.1439,  0.1448],\n",
      "        [-0.0281,  0.0259],\n",
      "        [-0.0958,  0.0964],\n",
      "        [-0.0285,  0.0271],\n",
      "        [-0.1319,  0.1303],\n",
      "        [-0.0769,  0.0743],\n",
      "        [-0.1563,  0.1562],\n",
      "        [-0.1727,  0.1713],\n",
      "        [-0.2174,  0.2095],\n",
      "        [-0.0740,  0.0692],\n",
      "        [ 0.1727, -0.1882],\n",
      "        [-0.2101,  0.2055],\n",
      "        [-0.0286,  0.0254],\n",
      "        [-0.2354,  0.2301],\n",
      "        [-0.1878,  0.1850],\n",
      "        [-0.0142,  0.0133],\n",
      "        [-0.0770,  0.0735],\n",
      "        [-0.3311,  0.3362],\n",
      "        [-0.2326,  0.2239],\n",
      "        [ 0.1379, -0.1399],\n",
      "        [-0.5195,  0.5197],\n",
      "        [-0.0247,  0.0120],\n",
      "        [-0.0938,  0.0940],\n",
      "        [-0.0821,  0.0776],\n",
      "        [-0.0918,  0.0920],\n",
      "        [-0.1192,  0.1166],\n",
      "        [-0.0049,  0.0074],\n",
      "        [-0.0832,  0.0862],\n",
      "        [ 0.0415, -0.0394],\n",
      "        [-0.1852,  0.1893],\n",
      "        [-0.1667,  0.1698],\n",
      "        [-0.1317,  0.1307],\n",
      "        [ 0.0122, -0.0117],\n",
      "        [-0.0094,  0.0017],\n",
      "        [-0.1031,  0.1044],\n",
      "        [-0.2761,  0.2766],\n",
      "        [-0.1970,  0.1922],\n",
      "        [-0.2954,  0.2989],\n",
      "        [-0.0293,  0.0230],\n",
      "        [-0.2739,  0.2743],\n",
      "        [-0.0474,  0.0431],\n",
      "        [-0.2686,  0.2689],\n",
      "        [-0.0896,  0.0906],\n",
      "        [-0.2525,  0.2543],\n",
      "        [-0.0726,  0.0765],\n",
      "        [ 0.1071, -0.1098],\n",
      "        [-0.1171,  0.1164],\n",
      "        [ 0.6552, -0.6714],\n",
      "        [-0.1893,  0.1965],\n",
      "        [-0.2454,  0.2390],\n",
      "        [-0.0417,  0.0372],\n",
      "        [ 0.0234, -0.0346],\n",
      "        [ 0.0859, -0.0898],\n",
      "        [-0.0682,  0.0642],\n",
      "        [-0.2854,  0.2848],\n",
      "        [-0.1930,  0.1883],\n",
      "        [-0.0105,  0.0035],\n",
      "        [-0.1691,  0.1635],\n",
      "        [-0.2089,  0.2032],\n",
      "        [-0.1825,  0.1762],\n",
      "        [-0.2637,  0.2572],\n",
      "        [-0.0497,  0.0470],\n",
      "        [-0.6149,  0.6116],\n",
      "        [-0.1902,  0.1860],\n",
      "        [-0.0109,  0.0092]], grad_fn=<AddmmBackward>)\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0.5213675213675214\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h = self.linear1(x)\n",
    "        #sigmoid_out = F.sigmoid(h)\n",
    "        y_pred = self.linear2(h) #.clamp(0,1)\n",
    "        #sigmoid2_out = F.sigmoid(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 100, 8, 100, 2 # batch !!!!!\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = M_NN(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "new_train_df.reset_index(drop=True, inplace=True)\n",
    "left_col = pd.DataFrame(data=np.where(new_train_df['Movement'] == 0, 1, 0)[:])\n",
    "data_train_y = pd.concat( [ left_col, new_train_df['Movement'] ], axis=1, ignore_index=True )\n",
    "\n",
    "new_test_df.reset_index(drop=True, inplace=True)\n",
    "left_col = pd.DataFrame(data=np.where(new_test_df['Movement'] == 0, 1, 0)[:])\n",
    "data_test_y = pd.concat( [ left_col, new_test_df['Movement'] ], axis=1, ignore_index=True )\n",
    "\n",
    "for t in range(3000):\n",
    "    for batch_num in range(N, len(normalize_train_x), N):\n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(torch.FloatTensor(normalize_train_x[batch_num-N:batch_num].values.tolist()))\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred,  torch.FloatTensor(data_train_y[batch_num-N:batch_num].values.tolist()))\n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%50 == 0):\n",
    "        print(t, loss.item())\n",
    "        \n",
    "    \n",
    "nn_predict_y = model.forward( torch.FloatTensor(normalize_test_x.values.tolist()))\n",
    "print(nn_predict_y)\n",
    "result = np.where(nn_predict_y[:, 0] > nn_predict_y[:, 1], 1, 0)\n",
    "print(result)\n",
    "\n",
    "print(accuracy_score(data_test_y[0], result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "    Open Price  Close Price  High Price  Low Price      S_10      Corr  \\\n",
      "18     2867.23      2872.87     2870.62    2851.48  2826.260  0.945994   \n",
      "19     2832.74      2853.53     2837.75    2818.27  2830.861  0.745889   \n",
      "20     2832.41      2822.43     2839.26    2813.04  2832.986  0.540062   \n",
      "21     2816.45      2823.81     2835.96    2812.70  2835.381  0.185381   \n",
      "22     2808.92      2821.98     2808.92    2759.97  2830.564 -0.300583   \n",
      "23     2741.06      2762.13     2763.39    2638.17  2812.161 -0.021433   \n",
      "24     2614.78      2648.94     2701.04    2593.07  2797.762  0.339436   \n",
      "25     2690.95      2695.14     2727.67    2681.33  2782.174  0.634603   \n",
      "26     2685.01      2681.66     2685.27    2580.56  2756.349  0.835768   \n",
      "27     2601.78      2581.00     2638.67    2532.69  2731.017  0.854726   \n",
      "28     2636.75      2619.55     2672.61    2622.45  2711.264  0.794333   \n",
      "29     2646.27      2656.00     2668.84    2637.08  2695.315  0.711992   \n",
      "30     2651.21      2662.94     2702.10    2648.87  2682.797  0.525232   \n",
      "31     2713.46      2698.63     2731.51    2689.82  2673.719  0.094092   \n",
      "32     2727.14      2731.20     2754.42    2725.11  2670.728 -0.432710   \n",
      "33     2722.99      2732.22     2737.60    2706.76  2677.460 -0.465086   \n",
      "34     2720.53      2716.26     2747.75    2701.29  2678.079 -0.692281   \n",
      "35     2710.42      2701.33     2731.26    2697.77  2680.309 -0.983363   \n",
      "36     2715.80      2703.96     2747.76    2713.74  2696.939 -0.802185   \n",
      "37     2757.37      2747.30     2780.64    2753.78  2712.944 -0.017694   \n",
      "\n",
      "    Open-Close  Open-Open  \n",
      "18       -5.64      19.75  \n",
      "19      -20.79     -34.49  \n",
      "20        9.98      -0.33  \n",
      "21       -7.36     -15.96  \n",
      "22      -13.06      -7.53  \n",
      "23      -21.07     -67.86  \n",
      "24      -34.16    -126.28  \n",
      "25       -4.19      76.17  \n",
      "26        3.35      -5.94  \n",
      "27       20.78     -83.23  \n",
      "28       17.20      34.97  \n",
      "29       -9.73       9.52  \n",
      "30      -11.73       4.94  \n",
      "31       14.83      62.25  \n",
      "32       -4.06      13.68  \n",
      "33       -9.23      -4.15  \n",
      "34        4.27      -2.46  \n",
      "35        9.09     -10.11  \n",
      "36       11.84       5.38  \n",
      "37       10.07      41.57  \n"
     ]
    }
   ],
   "source": [
    "print(data_test_y[1].values.tolist())\n",
    "print(data_test_x.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "- How did you preprocess this dataset ?\n",
    "- Which classifier reaches the highest classification accuracy in this dataset ?\n",
    "    - Why ?\n",
    "    - Can this result remain if the dataset is different ?\n",
    "- How did you improve your classifiers ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
