{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction - facebook inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1414, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price     Volume\n",
      "0  17-May-2012       38.00        38.00       38.00      38.00          0\n",
      "1  18-May-2012       42.05        38.23       45.00      38.00  580587712\n",
      "2  21-May-2012       36.53        34.03       36.66      33.00  168309824\n",
      "3  22-May-2012       32.61        31.00       33.59      30.94  102053824\n",
      "4  23-May-2012       31.37        32.00       32.50      31.36   73721136\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './fb-train.csv'\n",
    "test_data_path = './fb-test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1414, 4)\n",
      "   Open Price  Close Price  High Price  Low Price\n",
      "0       38.00        38.00       38.00      38.00\n",
      "1       42.05        38.23       45.00      38.00\n",
      "2       36.53        34.03       36.66      33.00\n",
      "3       32.61        31.00       33.59      30.94\n",
      "4       31.37        32.00       32.50      31.36\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "train_df.drop(columns=['Date', 'Volume'], inplace=True) # , 'Volume', 'High Price', 'Low Price'\n",
    "test_df.drop(columns=['Date', 'Volume'], inplace=True) # , 'Volume', 'High Price', 'Low Price'\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price  Tomorrow Movement  \\\n",
      "0       38.00        38.00       38.00      38.00                1.0   \n",
      "1       42.05        38.23       45.00      38.00                0.0   \n",
      "2       36.53        34.03       36.66      33.00                0.0   \n",
      "3       32.61        31.00       33.59      30.94                1.0   \n",
      "4       31.37        32.00       32.50      31.36                1.0   \n",
      "\n",
      "   Tomorrow Open  \n",
      "0          42.05  \n",
      "1          36.53  \n",
      "2          32.61  \n",
      "3          31.37  \n",
      "4          32.95  \n",
      "      Open Price  Close Price  High Price  Low Price  Tomorrow Movement  \\\n",
      "1409      177.14       177.20      177.53     176.23                0.0   \n",
      "1410      176.63       175.99      177.00     174.67                1.0   \n",
      "1411      176.55       177.62      178.44     176.26                1.0   \n",
      "1412      177.95       177.92      178.94     177.68                0.0   \n",
      "1413      178.00       176.46      178.85     176.46                NaN   \n",
      "\n",
      "      Tomorrow Open  \n",
      "1409         176.63  \n",
      "1410         176.55  \n",
      "1411         177.95  \n",
      "1412         178.00  \n",
      "1413            NaN  \n"
     ]
    }
   ],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with previous days as the training target\n",
    "# Add the column `Tomorrow Open` by shifting the column `Open Price` as one of the new features\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)\n",
    "\n",
    "train_df['Tomorrow Open'] = train_df['Open Price'].shift(-1)\n",
    "test_df['Tomorrow Open'] = test_df['Open Price'].shift(-1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1395, 10)\n",
      "    Open Price  Close Price  High Price  Low Price  Tomorrow Movement  \\\n",
      "18       27.66        27.27       28.10      27.10                1.0   \n",
      "19       27.65        28.29       28.32      27.38                1.0   \n",
      "20       28.50        30.01       30.10      28.35                1.0   \n",
      "21       29.95        31.41       32.08      29.41                1.0   \n",
      "22       31.53        31.91       32.18      30.70                0.0   \n",
      "\n",
      "    Tomorrow Open    S_10      Corr  Open-Close  Open-Open  \n",
      "18          27.65  27.198  0.544501        0.26       0.18  \n",
      "19          28.50  27.067 -0.230716        0.38      -0.01  \n",
      "20          29.95  27.296 -0.578315        0.21       0.85  \n",
      "21          31.53  27.747 -0.494005       -0.06       1.45  \n",
      "22          31.92  28.351 -0.079347        0.12       1.58  \n",
      "(233, 10)\n",
      "    Open Price  Close Price  High Price  Low Price  Tomorrow Movement  \\\n",
      "18      188.75       185.98      188.84     185.63                1.0   \n",
      "19      183.01       187.12      188.18     181.84                0.0   \n",
      "20      188.37       186.89      189.83     185.22                1.0   \n",
      "21      188.22       193.09      195.32     187.89                0.0   \n",
      "22      192.04       190.28      194.21     189.98                0.0   \n",
      "\n",
      "    Tomorrow Open     S_10      Corr  Open-Close  Open-Open  \n",
      "18         183.01  184.181 -0.687601       -1.25       1.00  \n",
      "19         188.37  185.054 -0.217268       -2.97      -5.74  \n",
      "20         188.22  185.983  0.066666        1.25       5.36  \n",
      "21         192.04  187.312  0.517322        1.33      -0.15  \n",
      "22         186.93  188.211  0.577841       -1.05       3.82  \n"
     ]
    }
   ],
   "source": [
    "# Add other new features `S_10`, `Corr`, `Open-Close`, `Open-Open` (explanation is described below)\n",
    "\n",
    "train_df['S_10'] = train_df['Close Price'].rolling(window=10).mean()\n",
    "train_df['Corr'] = train_df['Close Price'].rolling(window=10).corr(train_df['S_10'])\n",
    "train_df['Open-Close'] = train_df['Open Price'] - train_df['Close Price'].shift(1)\n",
    "train_df['Open-Open'] = train_df['Open Price'] - train_df['Open Price'].shift(1)\n",
    "train_df = train_df.dropna()\n",
    "new_train_df = train_df.iloc[:,:10]\n",
    "\n",
    "print(new_train_df.shape)\n",
    "print(new_train_df.head())\n",
    "\n",
    "test_df['S_10'] = test_df['Close Price'].rolling(window=10).mean()\n",
    "test_df['Corr'] = test_df['Close Price'].rolling(window=10).corr(test_df['S_10'])\n",
    "test_df['Open-Close'] = test_df['Open Price'] - test_df['Close Price'].shift(1)\n",
    "test_df['Open-Open'] = test_df['Open Price'] - test_df['Open Price'].shift(1)\n",
    "test_df = test_df.dropna()\n",
    "new_test_df = test_df.iloc[:,:10]\n",
    "\n",
    "print(new_test_df.shape)\n",
    "print(new_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1395, 9)\n",
      "    Open Price  Close Price  High Price  Low Price  Tomorrow Open    S_10  \\\n",
      "18       27.66        27.27       28.10      27.10          27.65  27.198   \n",
      "19       27.65        28.29       28.32      27.38          28.50  27.067   \n",
      "20       28.50        30.01       30.10      28.35          29.95  27.296   \n",
      "21       29.95        31.41       32.08      29.41          31.53  27.747   \n",
      "22       31.53        31.91       32.18      30.70          31.92  28.351   \n",
      "\n",
      "        Corr  Open-Close  Open-Open  \n",
      "18  0.544501        0.26       0.18  \n",
      "19 -0.230716        0.38      -0.01  \n",
      "20 -0.578315        0.21       0.85  \n",
      "21 -0.494005       -0.06       1.45  \n",
      "22 -0.079347        0.12       1.58  \n",
      "(1395,)\n",
      "18    1.0\n",
      "19    1.0\n",
      "20    1.0\n",
      "21    1.0\n",
      "22    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(233, 9)\n",
      "    Open Price  Close Price  High Price  Low Price  Tomorrow Open     S_10  \\\n",
      "18      188.75       185.98      188.84     185.63         183.01  184.181   \n",
      "19      183.01       187.12      188.18     181.84         188.37  185.054   \n",
      "20      188.37       186.89      189.83     185.22         188.22  185.983   \n",
      "21      188.22       193.09      195.32     187.89         192.04  187.312   \n",
      "22      192.04       190.28      194.21     189.98         186.93  188.211   \n",
      "\n",
      "        Corr  Open-Close  Open-Open  \n",
      "18 -0.687601       -1.25       1.00  \n",
      "19 -0.217268       -2.97      -5.74  \n",
      "20  0.066666        1.25       5.36  \n",
      "21  0.517322        1.33      -0.15  \n",
      "22  0.577841       -1.05       3.82  \n",
      "(233,)\n",
      "18    1.0\n",
      "19    0.0\n",
      "20    1.0\n",
      "21    0.0\n",
      "22    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "data_train_x = new_train_df.drop(columns=['Tomorrow Movement'])\n",
    "data_train_y = new_train_df['Tomorrow Movement']\n",
    "\n",
    "data_test_x = new_test_df.drop(columns=['Tomorrow Movement'])\n",
    "data_test_y = new_test_df['Tomorrow Movement']\n",
    "\n",
    "print(data_train_x.shape)\n",
    "print(data_train_x.head())\n",
    "print(data_train_y.shape)\n",
    "print(data_train_y.head())\n",
    "print('-----')\n",
    "print(data_test_x.shape)\n",
    "print(data_test_x.head())\n",
    "print(data_test_y.shape)\n",
    "print(data_test_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.6437275985663082\n",
      "\n",
      "testing accuracy:\n",
      "0.6824034334763949\n",
      "\n",
      "testing result prob:\n",
      "[[9.47158943e-01 5.28410566e-02]\n",
      " [2.82498932e-01 7.17501068e-01]\n",
      " [1.09052237e-01 8.90947763e-01]\n",
      " [8.29468155e-01 1.70531845e-01]\n",
      " [9.64185526e-01 3.58144741e-02]\n",
      " [8.97035663e-01 1.02964337e-01]\n",
      " [8.99641401e-01 1.00358599e-01]\n",
      " [1.26007199e-01 8.73992801e-01]\n",
      " [4.59912061e-03 9.95400879e-01]\n",
      " [3.01534758e-01 6.98465242e-01]\n",
      " [6.59958853e-01 3.40041147e-01]\n",
      " [2.21393329e-01 7.78606671e-01]\n",
      " [3.45070654e-01 6.54929346e-01]\n",
      " [7.09113590e-01 2.90886410e-01]\n",
      " [7.94337847e-01 2.05662153e-01]\n",
      " [2.28572772e-01 7.71427228e-01]\n",
      " [2.16521800e-01 7.83478200e-01]\n",
      " [2.02203819e-01 7.97796181e-01]\n",
      " [2.16278030e-01 7.83721970e-01]\n",
      " [5.83435658e-01 4.16564342e-01]\n",
      " [1.60501105e-01 8.39498895e-01]\n",
      " [1.53062274e-01 8.46937726e-01]\n",
      " [9.15266847e-01 8.47331527e-02]\n",
      " [6.61083524e-01 3.38916476e-01]\n",
      " [2.07255926e-01 7.92744074e-01]\n",
      " [6.26808624e-01 3.73191376e-01]\n",
      " [6.79557092e-01 3.20442908e-01]\n",
      " [8.88649148e-02 9.11135085e-01]\n",
      " [4.50749462e-01 5.49250538e-01]\n",
      " [1.92198145e-01 8.07801855e-01]\n",
      " [1.66474748e-01 8.33525252e-01]\n",
      " [7.25297227e-01 2.74702773e-01]\n",
      " [2.76558229e-01 7.23441771e-01]\n",
      " [9.99892548e-01 1.07452153e-04]\n",
      " [9.96239873e-01 3.76012692e-03]\n",
      " [9.83755526e-01 1.62444744e-02]\n",
      " [9.83418583e-01 1.65814167e-02]\n",
      " [1.97296996e-01 8.02703004e-01]\n",
      " [4.30350130e-02 9.56964987e-01]\n",
      " [9.91695826e-01 8.30417394e-03]\n",
      " [4.01552313e-01 5.98447687e-01]\n",
      " [4.64048893e-02 9.53595111e-01]\n",
      " [9.22244817e-01 7.77551828e-02]\n",
      " [1.22891485e-01 8.77108515e-01]\n",
      " [9.91442322e-01 8.55767751e-03]\n",
      " [7.70330587e-04 9.99229669e-01]\n",
      " [7.79131708e-01 2.20868292e-01]\n",
      " [2.37892648e-01 7.62107352e-01]\n",
      " [4.31483614e-01 5.68516386e-01]\n",
      " [6.74009260e-01 3.25990740e-01]\n",
      " [3.34740183e-01 6.65259817e-01]\n",
      " [2.01961430e-01 7.98038570e-01]\n",
      " [1.51631688e-01 8.48368312e-01]\n",
      " [1.82161719e-01 8.17838281e-01]\n",
      " [9.01431733e-01 9.85682672e-02]\n",
      " [4.65759576e-01 5.34240424e-01]\n",
      " [6.05440751e-01 3.94559249e-01]\n",
      " [1.56212692e-01 8.43787308e-01]\n",
      " [4.71100368e-01 5.28899632e-01]\n",
      " [1.98336071e-01 8.01663929e-01]\n",
      " [1.07401398e-07 9.99999893e-01]\n",
      " [2.40597805e-02 9.75940220e-01]\n",
      " [3.04154310e-01 6.95845690e-01]\n",
      " [3.70130961e-01 6.29869039e-01]\n",
      " [4.35974426e-01 5.64025574e-01]\n",
      " [7.34789278e-01 2.65210722e-01]\n",
      " [7.06086596e-01 2.93913404e-01]\n",
      " [3.64353010e-01 6.35646990e-01]\n",
      " [3.43849900e-01 6.56150100e-01]\n",
      " [2.63844024e-01 7.36155976e-01]\n",
      " [4.12700929e-01 5.87299071e-01]\n",
      " [7.14805117e-01 2.85194883e-01]\n",
      " [3.29369355e-01 6.70630645e-01]\n",
      " [8.32563269e-01 1.67436731e-01]\n",
      " [6.09851692e-01 3.90148308e-01]\n",
      " [5.35873045e-01 4.64126955e-01]\n",
      " [5.15190737e-01 4.84809263e-01]\n",
      " [1.30286895e-01 8.69713105e-01]\n",
      " [2.85271538e-01 7.14728462e-01]\n",
      " [7.09206657e-01 2.90793343e-01]\n",
      " [8.32110725e-01 1.67889275e-01]\n",
      " [3.83174464e-01 6.16825536e-01]\n",
      " [5.25824600e-01 4.74175400e-01]\n",
      " [2.44572699e-01 7.55427301e-01]\n",
      " [3.96890084e-01 6.03109916e-01]\n",
      " [2.27947978e-01 7.72052022e-01]\n",
      " [9.10358694e-01 8.96413062e-02]\n",
      " [2.26718900e-01 7.73281100e-01]\n",
      " [8.35400649e-01 1.64599351e-01]\n",
      " [6.31240647e-01 3.68759353e-01]\n",
      " [5.39859991e-01 4.60140009e-01]\n",
      " [5.49339655e-01 4.50660345e-01]\n",
      " [3.07309660e-01 6.92690340e-01]\n",
      " [2.93532535e-01 7.06467465e-01]\n",
      " [2.02265254e-01 7.97734746e-01]\n",
      " [7.97295103e-01 2.02704897e-01]\n",
      " [7.12832065e-01 2.87167935e-01]\n",
      " [9.36947279e-01 6.30527207e-02]\n",
      " [1.48726895e-01 8.51273105e-01]\n",
      " [2.94471730e-01 7.05528270e-01]\n",
      " [4.90400875e-01 5.09599125e-01]\n",
      " [8.69645362e-01 1.30354638e-01]\n",
      " [1.34178570e-01 8.65821430e-01]\n",
      " [3.94751066e-01 6.05248934e-01]\n",
      " [4.52699992e-01 5.47300008e-01]\n",
      " [1.86948806e-01 8.13051194e-01]\n",
      " [5.44933217e-01 4.55066783e-01]\n",
      " [9.73286790e-01 2.67132100e-02]\n",
      " [4.60301531e-02 9.53969847e-01]\n",
      " [5.23057692e-01 4.76942308e-01]\n",
      " [1.82975774e-01 8.17024226e-01]\n",
      " [5.16946754e-01 4.83053246e-01]\n",
      " [7.65128018e-01 2.34871982e-01]\n",
      " [1.98978201e-01 8.01021799e-01]\n",
      " [2.94711223e-01 7.05288777e-01]\n",
      " [3.40665887e-01 6.59334113e-01]\n",
      " [9.02283133e-01 9.77168666e-02]\n",
      " [6.81944850e-01 3.18055150e-01]\n",
      " [5.53065309e-01 4.46934691e-01]\n",
      " [1.85672884e-01 8.14327116e-01]\n",
      " [2.40989895e-01 7.59010105e-01]\n",
      " [5.32238044e-03 9.94677620e-01]\n",
      " [1.50093088e-01 8.49906912e-01]\n",
      " [1.00000000e+00 2.47653043e-22]\n",
      " [4.81197563e-02 9.51880244e-01]\n",
      " [1.01435551e-01 8.98564449e-01]\n",
      " [3.38851521e-01 6.61148479e-01]\n",
      " [8.48130730e-02 9.15186927e-01]\n",
      " [4.54332099e-01 5.45667901e-01]\n",
      " [2.04998165e-01 7.95001835e-01]\n",
      " [1.11016577e-01 8.88983423e-01]\n",
      " [4.34243321e-01 5.65756679e-01]\n",
      " [1.34554090e-01 8.65445910e-01]\n",
      " [2.73573671e-01 7.26426329e-01]\n",
      " [6.59085773e-01 3.40914227e-01]\n",
      " [4.39722021e-01 5.60277979e-01]\n",
      " [2.35347642e-01 7.64652358e-01]\n",
      " [8.63852652e-01 1.36147348e-01]\n",
      " [2.81941098e-01 7.18058902e-01]\n",
      " [2.97657668e-01 7.02342332e-01]\n",
      " [3.02341367e-01 6.97658633e-01]\n",
      " [2.69470283e-01 7.30529717e-01]\n",
      " [4.78071755e-01 5.21928245e-01]\n",
      " [5.75024700e-01 4.24975300e-01]\n",
      " [1.69978689e-01 8.30021311e-01]\n",
      " [1.30540369e-01 8.69459631e-01]\n",
      " [2.61846083e-01 7.38153917e-01]\n",
      " [3.45521606e-01 6.54478394e-01]\n",
      " [4.12371686e-01 5.87628314e-01]\n",
      " [6.05583369e-01 3.94416631e-01]\n",
      " [8.93835440e-01 1.06164560e-01]\n",
      " [8.31083557e-01 1.68916443e-01]\n",
      " [3.73928485e-01 6.26071515e-01]\n",
      " [8.57525210e-01 1.42474790e-01]\n",
      " [3.28796490e-01 6.71203510e-01]\n",
      " [4.54174311e-01 5.45825689e-01]\n",
      " [9.47122447e-01 5.28775530e-02]\n",
      " [3.46304818e-01 6.53695182e-01]\n",
      " [2.54071541e-01 7.45928459e-01]\n",
      " [5.33497732e-01 4.66502268e-01]\n",
      " [6.95047957e-01 3.04952043e-01]\n",
      " [4.88562995e-01 5.11437005e-01]\n",
      " [1.74274385e-01 8.25725615e-01]\n",
      " [2.78476329e-01 7.21523671e-01]\n",
      " [8.04986877e-01 1.95013123e-01]\n",
      " [9.88781490e-01 1.12185105e-02]\n",
      " [7.46257365e-01 2.53742635e-01]\n",
      " [3.46432938e-01 6.53567062e-01]\n",
      " [5.96784231e-01 4.03215769e-01]\n",
      " [7.58667617e-01 2.41332383e-01]\n",
      " [6.42218530e-01 3.57781470e-01]\n",
      " [1.90593268e-01 8.09406732e-01]\n",
      " [7.38213821e-01 2.61786179e-01]\n",
      " [2.73134037e-01 7.26865963e-01]\n",
      " [8.03910044e-01 1.96089956e-01]\n",
      " [3.53882128e-01 6.46117872e-01]\n",
      " [6.58556198e-01 3.41443802e-01]\n",
      " [5.94759930e-01 4.05240070e-01]\n",
      " [2.12708032e-02 9.78729197e-01]\n",
      " [4.49273468e-01 5.50726532e-01]\n",
      " [6.67407483e-02 9.33259252e-01]\n",
      " [3.10102907e-01 6.89897093e-01]\n",
      " [6.87073625e-01 3.12926375e-01]\n",
      " [1.68467279e-01 8.31532721e-01]\n",
      " [1.86265227e-01 8.13734773e-01]\n",
      " [9.74454178e-01 2.55458217e-02]\n",
      " [6.15345894e-01 3.84654106e-01]\n",
      " [3.80308548e-02 9.61969145e-01]\n",
      " [9.97546387e-01 2.45361337e-03]\n",
      " [1.85512053e-02 9.81448795e-01]\n",
      " [8.19992878e-01 1.80007122e-01]\n",
      " [6.91067060e-05 9.99930893e-01]\n",
      " [3.73024731e-01 6.26975269e-01]\n",
      " [4.65772560e-01 5.34227440e-01]\n",
      " [4.70085356e-01 5.29914644e-01]\n",
      " [2.48906277e-01 7.51093723e-01]\n",
      " [1.12613955e-01 8.87386045e-01]\n",
      " [7.19876997e-01 2.80123003e-01]\n",
      " [7.03694271e-01 2.96305729e-01]\n",
      " [5.17211360e-01 4.82788640e-01]\n",
      " [2.29108370e-01 7.70891630e-01]\n",
      " [8.25473729e-02 9.17452627e-01]\n",
      " [8.72989803e-01 1.27010197e-01]\n",
      " [9.63613541e-01 3.63864589e-02]\n",
      " [8.68920584e-01 1.31079416e-01]\n",
      " [9.85523106e-01 1.44768945e-02]\n",
      " [1.43773604e-01 8.56226396e-01]\n",
      " [6.73565003e-01 3.26434997e-01]\n",
      " [1.06387378e-01 8.93612622e-01]\n",
      " [6.95294284e-01 3.04705716e-01]\n",
      " [1.35313412e-01 8.64686588e-01]\n",
      " [7.59276803e-01 2.40723197e-01]\n",
      " [6.65530105e-01 3.34469895e-01]\n",
      " [7.45925487e-02 9.25407451e-01]\n",
      " [4.80376311e-01 5.19623689e-01]\n",
      " [2.24676230e-02 9.77532377e-01]\n",
      " [9.83898418e-01 1.61015820e-02]\n",
      " [8.01049316e-01 1.98950684e-01]\n",
      " [4.59979204e-02 9.54002080e-01]\n",
      " [8.56610687e-02 9.14338931e-01]\n",
      " [1.62210265e-01 8.37789735e-01]\n",
      " [2.04747579e-01 7.95252421e-01]\n",
      " [8.52357794e-01 1.47642206e-01]\n",
      " [7.44291655e-01 2.55708345e-01]\n",
      " [1.84995966e-01 8.15004034e-01]\n",
      " [9.52468711e-01 4.75312893e-02]\n",
      " [8.65916715e-01 1.34083285e-01]\n",
      " [5.22282672e-01 4.77717328e-01]\n",
      " [7.07821591e-01 2.92178409e-01]\n",
      " [5.36968600e-02 9.46303140e-01]\n",
      " [9.47804081e-01 5.21959193e-02]\n",
      " [3.50504848e-01 6.49495152e-01]\n",
      " [1.19573147e-01 8.80426853e-01]]\n",
      "\n",
      "predicted testing labels:\n",
      "[0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "#lr_model = SGDClassifier(loss='log',  max_iter=800)\n",
    "lr_model.fit(data_train_x, data_train_y)\n",
    "\n",
    "predict_train_y = lr_model.predict(data_train_x)\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(data_train_y, predict_train_y))\n",
    "\n",
    "lr_predict_test_y = lr_model.predict(data_test_x)\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(data_test_y, lr_predict_test_y))\n",
    "\n",
    "print('\\ntesting result prob:')\n",
    "print(lr_model.predict_proba(data_test_x))\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.6849727015269627, 0.6824034334763949, 0.6804216988464749, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(69, 45, 29, 90)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(data_test_y, lr_predict_test_y, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(data_test_y, lr_predict_test_y).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Close Price      Corr  High Price  Low Price  Open Price  Open-Close  \\\n",
      "0    -0.756711  0.106105   -0.750319  -0.746640   -0.746098    0.300000   \n",
      "1    -0.742186 -0.833286   -0.747197  -0.742637   -0.746241    0.500000   \n",
      "2    -0.717693 -1.254500   -0.721930  -0.728768   -0.734127    0.216667   \n",
      "3    -0.697757 -1.152335   -0.693825  -0.713612   -0.713461   -0.233333   \n",
      "4    -0.690637 -0.649861   -0.692406  -0.695167   -0.690943    0.066667   \n",
      "\n",
      "   Open-Open      S_10  Tomorrow Open  \n",
      "0   0.053691 -0.745188      -0.745710  \n",
      "1  -0.073826 -0.747052      -0.733604  \n",
      "2   0.503356 -0.743794      -0.712953  \n",
      "3   0.906040 -0.737377      -0.690451  \n",
      "4   0.993289 -0.728785      -0.684896  \n",
      "[ 1  1  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(data_train_x) #scaler.fit(train_df.append(test_df, ignore_index=True))\n",
    "\n",
    "train_normalize = scaler.transform(data_train_x)\n",
    "train_normalize = np.transpose(train_normalize)\n",
    "\n",
    "normalize_train_x = pd.DataFrame({\n",
    "    'Open Price': train_normalize[0],\n",
    "    'Close Price': train_normalize[1],\n",
    "    'High Price': train_normalize[2],\n",
    "    'Low Price': train_normalize[3],\n",
    "    'Tomorrow Open': train_normalize[4],\n",
    "    'S_10': train_normalize[5],\n",
    "    'Corr': train_normalize[6],\n",
    "    'Open-Close': train_normalize[7],\n",
    "    'Open-Open': train_normalize[8],\n",
    "})\n",
    "\n",
    "test_normalize = scaler.transform(data_test_x)\n",
    "test_normalize = np.transpose(test_normalize)\n",
    "normalize_test_x = pd.DataFrame({\n",
    "    'Open Price': test_normalize[0],\n",
    "    'Close Price': test_normalize[1],\n",
    "    'High Price': test_normalize[2],\n",
    "    'Low Price': test_normalize[3],\n",
    "    'Tomorrow Open': test_normalize[4],\n",
    "    'S_10': test_normalize[5],\n",
    "    'Corr': test_normalize[6],\n",
    "    'Open-Close': test_normalize[7],\n",
    "    'Open-Open': test_normalize[8],\n",
    "})\n",
    "\n",
    "data_train_y = np.where(data_train_y == 0, -1, 1)\n",
    "data_test_y = np.where(data_test_y == 0, -1, 1)\n",
    "\n",
    "print(normalize_train_x.head())\n",
    "print(data_train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.6379928315412187\n",
      "\n",
      "testing accuracy:\n",
      "0.6824034334763949\n",
      "[-1  1  1 -1 -1 -1 -1  1  1  1 -1  1  1 -1 -1  1  1  1  1 -1  1  1 -1 -1\n",
      "  1 -1 -1  1  1  1  1 -1  1 -1 -1 -1 -1  1  1 -1 -1  1 -1  1 -1  1 -1  1\n",
      "  1 -1  1  1  1  1 -1  1 -1  1  1  1  1  1  1  1  1 -1 -1  1  1  1  1 -1\n",
      "  1 -1 -1 -1  1  1  1 -1 -1  1 -1  1  1  1 -1  1 -1 -1 -1 -1  1  1  1 -1\n",
      " -1 -1  1  1  1 -1  1  1 -1  1 -1 -1  1 -1  1 -1 -1  1  1  1 -1 -1 -1  1\n",
      "  1  1  1 -1  1  1  1  1 -1  1  1 -1  1  1 -1  1  1 -1  1  1  1  1  1 -1\n",
      "  1  1  1  1  1 -1 -1 -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1 -1 -1 -1  1\n",
      " -1 -1 -1  1 -1  1 -1  1 -1 -1  1 -1  1  1 -1  1  1 -1 -1  1 -1  1 -1  1\n",
      " -1  1 -1  1  1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1  1 -1  1 -1 -1  1  1  1\n",
      " -1 -1  1  1  1  1 -1 -1  1 -1 -1 -1 -1  1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel='linear', C=3000, tol=1e-5)\n",
    "svc_model.fit(normalize_train_x, data_train_y)\n",
    "\n",
    "predict_train_y = svc_model.predict(normalize_train_x)\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(data_train_y, predict_train_y))\n",
    "\n",
    "svc_predict_test_y = svc_model.predict(normalize_test_x)\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(data_test_y, svc_predict_test_y))\n",
    "print(svc_predict_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.6831712054788209, 0.6824034334763949, 0.6815222651392658, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(72, 42, 32, 87)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(data_test_y, svc_predict_test_y, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(data_test_y, svc_predict_test_y).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1395, 9)\n",
      "   Close Price      Corr  High Price  Low Price  Open Price  Open-Close  \\\n",
      "0    -0.756711  0.106105   -0.750319  -0.746640   -0.746098    0.300000   \n",
      "1    -0.742186 -0.833286   -0.747197  -0.742637   -0.746241    0.500000   \n",
      "2    -0.717693 -1.254500   -0.721930  -0.728768   -0.734127    0.216667   \n",
      "3    -0.697757 -1.152335   -0.693825  -0.713612   -0.713461   -0.233333   \n",
      "4    -0.690637 -0.649861   -0.692406  -0.695167   -0.690943    0.066667   \n",
      "\n",
      "   Open-Open      S_10  Tomorrow Open  \n",
      "0   0.053691 -0.745188      -0.745710  \n",
      "1  -0.073826 -0.747052      -0.733604  \n",
      "2   0.503356 -0.743794      -0.712953  \n",
      "3   0.906040 -0.737377      -0.690451  \n",
      "4   0.993289 -0.728785      -0.684896  \n",
      "(1395, 2)\n",
      "   0  1\n",
      "0  0  1\n",
      "1  0  1\n",
      "2  0  1\n",
      "3  0  1\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "left_col = pd.DataFrame(data=np.where(data_train_y == -1, 1, 0)[:])\n",
    "data_train_y = pd.DataFrame(data=np.where(data_train_y == -1, 0, 1)[:])\n",
    "data_train_y = pd.concat( [ left_col, data_train_y ], axis=1, ignore_index=True )\n",
    "\n",
    "left_col = pd.DataFrame(data=np.where(data_test_y == -1, 1, 0)[:])\n",
    "data_test_y = pd.DataFrame(data=np.where(data_test_y == -1, 0, 1)[:])\n",
    "data_test_y = pd.concat( [ left_col, data_test_y ], axis=1, ignore_index=True )\n",
    "\n",
    "print(normalize_train_x.shape)\n",
    "print(normalize_train_x.head())\n",
    "\n",
    "print(data_train_y.shape)\n",
    "print(data_train_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 409.946533203125\n",
      "100 409.06732177734375\n",
      "200 408.2174987792969\n",
      "300 407.1663818359375\n",
      "400 405.8822326660156\n",
      "500 404.51605224609375\n",
      "600 404.3182373046875\n",
      "700 403.8816223144531\n",
      "800 403.02685546875\n",
      "900 403.74755859375\n",
      "1000 402.9700927734375\n",
      "1100 402.6396484375\n",
      "1200 402.3293151855469\n",
      "1300 402.01214599609375\n",
      "1400 401.6769104003906\n",
      "1500 401.3251037597656\n",
      "1600 400.96319580078125\n",
      "1700 400.59814453125\n",
      "1800 400.23516845703125\n",
      "1900 399.8778076171875\n",
      "2000 399.528076171875\n",
      "2100 399.18695068359375\n",
      "2200 398.8548889160156\n",
      "2300 398.5320129394531\n",
      "2400 398.2181091308594\n",
      "2500 397.91265869140625\n",
      "2600 397.6156005859375\n",
      "2700 397.32611083984375\n",
      "2800 397.044189453125\n",
      "2900 396.7690124511719\n",
      "3000 396.5002136230469\n",
      "3100 396.2375793457031\n",
      "3200 395.9805603027344\n",
      "3300 395.72857666015625\n",
      "3400 395.4812927246094\n",
      "3500 395.23846435546875\n",
      "3600 394.99969482421875\n",
      "3700 394.7644958496094\n",
      "3800 394.5328063964844\n",
      "3900 394.304443359375\n",
      "4000 394.07904052734375\n",
      "4100 393.8563537597656\n",
      "4200 393.6362609863281\n",
      "4300 393.4186706542969\n",
      "4400 393.2033386230469\n",
      "4500 392.990234375\n",
      "4600 392.779296875\n",
      "4700 392.5701599121094\n",
      "4800 392.3630676269531\n",
      "4900 392.157958984375\n",
      "5000 391.9544982910156\n",
      "5100 391.7528991699219\n",
      "5200 391.5530700683594\n",
      "5300 391.3548583984375\n",
      "5400 391.1583251953125\n",
      "5500 390.9634094238281\n",
      "5600 390.7702941894531\n",
      "5700 390.57867431640625\n",
      "5800 390.3887023925781\n",
      "5900 390.2002258300781\n",
      "6000 390.0135192871094\n",
      "6100 389.8282165527344\n",
      "6200 389.64453125\n",
      "6300 389.4623718261719\n",
      "6400 389.2817687988281\n",
      "6500 389.1027526855469\n",
      "6600 388.9251708984375\n",
      "6700 388.7491455078125\n",
      "6800 388.5747985839844\n",
      "6900 388.40179443359375\n",
      "7000 388.2303466796875\n",
      "7100 388.0602111816406\n",
      "7200 387.891845703125\n",
      "7300 387.72479248046875\n",
      "7400 387.5593566894531\n",
      "7500 387.3953552246094\n",
      "7600 387.23284912109375\n",
      "7700 387.07183837890625\n",
      "7800 386.9121398925781\n",
      "7900 386.7540588378906\n",
      "8000 386.5973205566406\n",
      "8100 386.44207763671875\n",
      "8200 386.288330078125\n",
      "8300 386.13592529296875\n",
      "8400 385.9850158691406\n",
      "8500 385.8355407714844\n",
      "8600 385.68756103515625\n",
      "8700 385.5409240722656\n",
      "8800 385.395751953125\n",
      "8900 385.25201416015625\n",
      "9000 385.109619140625\n",
      "9100 384.9686584472656\n",
      "9200 384.82916259765625\n",
      "9300 384.6910400390625\n",
      "9400 384.5543518066406\n",
      "9500 384.4189453125\n",
      "9600 384.28509521484375\n",
      "9700 384.15252685546875\n",
      "9800 384.0214538574219\n",
      "9900 383.8919372558594\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        acti_out = F.relu(h)\n",
    "        y_pred = self.linear2(h) #.clamp(0,1)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size\n",
    "N, D_in, H, D_out = 300, 9, 100, 2\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "for t in range(10000):\n",
    "    for batch_num in range(N, len(normalize_train_x), N):\n",
    "        \n",
    "        y_pred = model(torch.FloatTensor(normalize_train_x[batch_num-N:batch_num].values.tolist()))\n",
    "\n",
    "        loss = criterion(y_pred, torch.FloatTensor(data_train_y[batch_num-N:batch_num].values.tolist()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%100 == 0):\n",
    "        print(t, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.617921146953405\n",
      "\n",
      "testing accuracy:\n",
      "0.6437768240343348\n",
      "predicted testing prob:\n",
      "tensor([[ 1.3561e+00, -1.3567e+00],\n",
      "        [-2.5659e+00,  2.5644e+00],\n",
      "        [-7.3496e-01,  7.3416e-01],\n",
      "        [ 1.2218e+00, -1.2242e+00],\n",
      "        [ 2.0628e+00, -2.0644e+00],\n",
      "        [ 6.8311e-02, -7.3388e-02],\n",
      "        [-7.9516e-01,  7.9322e-01],\n",
      "        [-1.2471e+00,  1.2456e+00],\n",
      "        [-3.5335e+00,  3.5291e+00],\n",
      "        [-1.0463e+00,  1.0456e+00],\n",
      "        [ 2.7909e-01, -2.7901e-01],\n",
      "        [-1.7643e+00,  1.7639e+00],\n",
      "        [-1.1007e+00,  1.0994e+00],\n",
      "        [ 1.0446e+00, -1.0440e+00],\n",
      "        [ 2.7929e-02, -2.8636e-02],\n",
      "        [-2.0660e+00,  2.0653e+00],\n",
      "        [-6.4772e-01,  6.4583e-01],\n",
      "        [-8.1421e-01,  8.1420e-01],\n",
      "        [-8.5201e-01,  8.5182e-01],\n",
      "        [ 7.3509e-01, -7.3477e-01],\n",
      "        [-1.5227e+00,  1.5220e+00],\n",
      "        [-1.3399e+00,  1.3383e+00],\n",
      "        [ 1.1476e+00, -1.1492e+00],\n",
      "        [-1.5360e+00,  1.5353e+00],\n",
      "        [-1.1081e+00,  1.1072e+00],\n",
      "        [ 1.0450e+00, -1.0453e+00],\n",
      "        [-6.2274e-01,  6.2178e-01],\n",
      "        [-1.4260e+00,  1.4258e+00],\n",
      "        [-1.4506e-01,  1.4540e-01],\n",
      "        [-1.2929e+00,  1.2930e+00],\n",
      "        [-1.0701e+00,  1.0688e+00],\n",
      "        [-1.0026e-01,  1.0054e-01],\n",
      "        [-1.5114e+00,  1.5120e+00],\n",
      "        [ 5.7727e+00, -5.7722e+00],\n",
      "        [-9.7582e-04, -1.1992e-03],\n",
      "        [-5.2265e-01,  5.2106e-01],\n",
      "        [ 1.1912e+00, -1.1950e+00],\n",
      "        [-1.9915e+00,  1.9888e+00],\n",
      "        [-2.0894e+00,  2.0862e+00],\n",
      "        [ 2.1859e+00, -2.1866e+00],\n",
      "        [-1.6371e+00,  1.6308e+00],\n",
      "        [-3.1512e+00,  3.1496e+00],\n",
      "        [ 2.3004e+00, -2.3021e+00],\n",
      "        [-1.9351e+00,  1.9336e+00],\n",
      "        [ 2.7763e+00, -2.7767e+00],\n",
      "        [-7.0751e+00,  7.0743e+00],\n",
      "        [ 3.5262e+00, -3.5262e+00],\n",
      "        [-1.7191e+00,  1.7167e+00],\n",
      "        [-1.6894e-01,  1.6772e-01],\n",
      "        [ 3.8306e-01, -3.8546e-01],\n",
      "        [ 3.7726e-01, -3.7855e-01],\n",
      "        [-6.6685e-01,  6.6571e-01],\n",
      "        [-1.5314e+00,  1.5314e+00],\n",
      "        [-9.5382e-01,  9.5415e-01],\n",
      "        [ 1.3731e+00, -1.3734e+00],\n",
      "        [-9.0178e-01,  9.0135e-01],\n",
      "        [-3.5755e-01,  3.5750e-01],\n",
      "        [-1.4256e+00,  1.4253e+00],\n",
      "        [-1.6388e-01,  1.6317e-01],\n",
      "        [-1.3129e+00,  1.3102e+00],\n",
      "        [-1.1625e+01,  1.1625e+01],\n",
      "        [ 2.9984e+00, -2.9987e+00],\n",
      "        [ 4.9463e-01, -4.9563e-01],\n",
      "        [-7.6214e-01,  7.6050e-01],\n",
      "        [-8.8300e-01,  8.8288e-01],\n",
      "        [ 8.0947e-01, -8.1072e-01],\n",
      "        [ 6.3643e-03, -7.0779e-03],\n",
      "        [-1.3330e+00,  1.3323e+00],\n",
      "        [-7.5623e-02,  7.5258e-02],\n",
      "        [-1.0668e+00,  1.0673e+00],\n",
      "        [-3.3680e-01,  3.3637e-01],\n",
      "        [ 6.9911e-01, -6.9950e-01],\n",
      "        [-8.6309e-01,  8.6212e-01],\n",
      "        [ 1.1121e+00, -1.1119e+00],\n",
      "        [-1.1361e+00,  1.1362e+00],\n",
      "        [-7.8782e-01,  7.8798e-01],\n",
      "        [-8.5611e-01,  8.5646e-01],\n",
      "        [-1.7718e+00,  1.7719e+00],\n",
      "        [-7.7926e-01,  7.7949e-01],\n",
      "        [ 4.1010e-01, -4.0994e-01],\n",
      "        [-9.0437e-02,  8.9853e-02],\n",
      "        [-7.4089e-01,  7.4127e-01],\n",
      "        [-3.8782e-01,  3.8805e-01],\n",
      "        [-1.6271e+00,  1.6267e+00],\n",
      "        [-3.9439e-01,  3.9473e-01],\n",
      "        [-1.0239e+00,  1.0228e+00],\n",
      "        [ 1.9782e+00, -1.9780e+00],\n",
      "        [-2.1524e+00,  2.1522e+00],\n",
      "        [ 1.2156e+00, -1.2159e+00],\n",
      "        [-1.1664e+00,  1.1661e+00],\n",
      "        [-5.8860e-01,  5.8796e-01],\n",
      "        [-1.0666e+00,  1.0666e+00],\n",
      "        [-9.5314e-01,  9.5253e-01],\n",
      "        [-5.4249e-01,  5.4291e-01],\n",
      "        [-1.1136e+00,  1.1133e+00],\n",
      "        [ 6.9622e-01, -6.9680e-01],\n",
      "        [ 7.9227e-02, -7.9263e-02],\n",
      "        [ 9.2754e-01, -9.2891e-01],\n",
      "        [-2.2749e+00,  2.2748e+00],\n",
      "        [-1.5232e-01,  1.5119e-01],\n",
      "        [ 1.1814e-01, -1.1837e-01],\n",
      "        [ 3.2824e-01, -3.2811e-01],\n",
      "        [-2.3815e+00,  2.3801e+00],\n",
      "        [-8.6254e-01,  8.6296e-01],\n",
      "        [-1.1559e-01,  1.1383e-01],\n",
      "        [-2.2005e+00,  2.2002e+00],\n",
      "        [ 3.0621e-01, -3.0670e-01],\n",
      "        [ 1.0815e+00, -1.0820e+00],\n",
      "        [-3.1550e+00,  3.1546e+00],\n",
      "        [ 1.9454e-01, -1.9475e-01],\n",
      "        [-9.8553e-01,  9.8468e-01],\n",
      "        [ 8.3180e-01, -8.3160e-01],\n",
      "        [ 1.7895e-01, -1.7891e-01],\n",
      "        [-1.9760e+00,  1.9753e+00],\n",
      "        [-7.0880e-01,  7.0854e-01],\n",
      "        [-2.1825e-01,  2.1857e-01],\n",
      "        [ 9.8151e-01, -9.8162e-01],\n",
      "        [-1.0198e+00,  1.0185e+00],\n",
      "        [ 9.6761e-02, -9.6841e-02],\n",
      "        [-1.8294e+00,  1.8291e+00],\n",
      "        [-1.0459e+00,  1.0455e+00],\n",
      "        [-3.7559e+00,  3.7562e+00],\n",
      "        [ 9.0174e-02, -9.0123e-02],\n",
      "        [ 3.2881e+01, -3.2882e+01],\n",
      "        [-2.0387e+01,  2.0382e+01],\n",
      "        [-4.4894e-01,  4.4816e-01],\n",
      "        [-1.6531e+00,  1.6520e+00],\n",
      "        [-3.0317e+00,  3.0313e+00],\n",
      "        [ 5.3615e-03, -5.7964e-03],\n",
      "        [-2.2799e+00,  2.2789e+00],\n",
      "        [-8.6833e-01,  8.6888e-01],\n",
      "        [-1.6085e-01,  1.5957e-01],\n",
      "        [-2.5902e-01,  2.5742e-01],\n",
      "        [-7.8524e-01,  7.8466e-01],\n",
      "        [ 6.3430e-01, -6.3536e-01],\n",
      "        [-1.2712e+00,  1.2710e+00],\n",
      "        [-1.2742e+00,  1.2732e+00],\n",
      "        [ 1.0521e+00, -1.0520e+00],\n",
      "        [-1.8097e+00,  1.8092e+00],\n",
      "        [-3.3432e-01,  3.3239e-01],\n",
      "        [-1.7298e+00,  1.7290e+00],\n",
      "        [-1.1191e+00,  1.1190e+00],\n",
      "        [-5.7677e-01,  5.7672e-01],\n",
      "        [-5.4025e-01,  5.4044e-01],\n",
      "        [-1.4672e+00,  1.4663e+00],\n",
      "        [-1.5610e+00,  1.5617e+00],\n",
      "        [-4.2153e-01,  4.2124e-01],\n",
      "        [-3.8589e-01,  3.8587e-01],\n",
      "        [-8.7418e-01,  8.7449e-01],\n",
      "        [ 6.0132e-02, -6.1359e-02],\n",
      "        [ 1.0715e+00, -1.0716e+00],\n",
      "        [-4.1955e-01,  4.1866e-01],\n",
      "        [-1.5931e+00,  1.5916e+00],\n",
      "        [ 4.2210e-01, -4.2364e-01],\n",
      "        [-2.4300e+00,  2.4288e+00],\n",
      "        [-2.5527e-01,  2.5556e-01],\n",
      "        [ 1.4014e+00, -1.4019e+00],\n",
      "        [-1.7802e+00,  1.7796e+00],\n",
      "        [-1.3402e+00,  1.3399e+00],\n",
      "        [-4.3976e-01,  4.4010e-01],\n",
      "        [-8.8566e-02,  8.8701e-02],\n",
      "        [-1.1345e+00,  1.1339e+00],\n",
      "        [-1.5051e+00,  1.5047e+00],\n",
      "        [-1.2826e-01,  1.2857e-01],\n",
      "        [ 1.2133e+00, -1.2147e+00],\n",
      "        [ 1.3574e+00, -1.3584e+00],\n",
      "        [-5.7968e-01,  5.7893e-01],\n",
      "        [-4.5782e-01,  4.5612e-01],\n",
      "        [ 7.2671e-01, -7.2840e-01],\n",
      "        [ 4.9708e-01, -4.9877e-01],\n",
      "        [-8.5525e-01,  8.5346e-01],\n",
      "        [-1.7109e+00,  1.7101e+00],\n",
      "        [ 3.7352e-01, -3.7424e-01],\n",
      "        [-1.1656e+00,  1.1651e+00],\n",
      "        [ 5.4048e-01, -5.4181e-01],\n",
      "        [-1.8495e+00,  1.8489e+00],\n",
      "        [ 5.2559e-01, -5.2658e-01],\n",
      "        [-2.9739e-01,  2.9484e-01],\n",
      "        [-4.1212e+00,  4.1198e+00],\n",
      "        [ 1.2549e+00, -1.2556e+00],\n",
      "        [-2.6499e+00,  2.6491e+00],\n",
      "        [-1.0655e-01,  1.0592e-01],\n",
      "        [ 8.4389e-01, -8.4378e-01],\n",
      "        [-1.6873e+00,  1.6860e+00],\n",
      "        [-1.1867e+00,  1.1856e+00],\n",
      "        [ 2.3198e+00, -2.3208e+00],\n",
      "        [-1.5612e+00,  1.5605e+00],\n",
      "        [-1.7037e+00,  1.7001e+00],\n",
      "        [ 3.3809e+00, -3.3821e+00],\n",
      "        [-4.7016e+00,  4.6996e+00],\n",
      "        [ 2.1230e+00, -2.1258e+00],\n",
      "        [-8.4507e+00,  8.4490e+00],\n",
      "        [ 3.9707e+00, -3.9721e+00],\n",
      "        [-9.7277e-01,  9.7249e-01],\n",
      "        [-1.2449e-01,  1.2270e-01],\n",
      "        [-1.3764e+00,  1.3763e+00],\n",
      "        [-1.5755e+00,  1.5753e+00],\n",
      "        [ 1.1234e+00, -1.1237e+00],\n",
      "        [-3.8336e-02,  3.7370e-02],\n",
      "        [-9.4768e-01,  9.4676e-01],\n",
      "        [-1.5017e+00,  1.5006e+00],\n",
      "        [-2.0271e+00,  2.0260e+00],\n",
      "        [ 1.5089e+00, -1.5092e+00],\n",
      "        [ 9.9973e-01, -1.0003e+00],\n",
      "        [-1.6489e-01,  1.6419e-01],\n",
      "        [ 1.6644e+00, -1.6668e+00],\n",
      "        [-4.1175e+00,  4.1149e+00],\n",
      "        [ 1.6246e+00, -1.6253e+00],\n",
      "        [-2.2101e+00,  2.2094e+00],\n",
      "        [ 4.7467e-01, -4.7533e-01],\n",
      "        [-1.5018e+00,  1.5016e+00],\n",
      "        [ 6.5623e-01, -6.5596e-01],\n",
      "        [-6.1102e-02,  5.9930e-02],\n",
      "        [-1.8100e+00,  1.8097e+00],\n",
      "        [ 1.1696e+00, -1.1701e+00],\n",
      "        [-2.6562e+00,  2.6534e+00],\n",
      "        [ 3.8016e+00, -3.8042e+00],\n",
      "        [-1.3543e+00,  1.3528e+00],\n",
      "        [-1.5702e+00,  1.5690e+00],\n",
      "        [-1.0823e+00,  1.0815e+00],\n",
      "        [-2.8708e-01,  2.8709e-01],\n",
      "        [-7.7484e-01,  7.7308e-01],\n",
      "        [ 1.3619e+00, -1.3617e+00],\n",
      "        [-3.0598e-01,  3.0483e-01],\n",
      "        [-1.3986e+00,  1.3963e+00],\n",
      "        [ 1.8548e+00, -1.8567e+00],\n",
      "        [ 1.0840e+00, -1.0904e+00],\n",
      "        [-2.1578e+00,  2.1559e+00],\n",
      "        [ 1.1463e+00, -1.1509e+00],\n",
      "        [-3.5836e+00,  3.5798e+00],\n",
      "        [ 2.4977e+00, -2.4994e+00],\n",
      "        [-6.6688e-01,  6.6652e-01],\n",
      "        [-9.9265e-01,  9.9199e-01]], grad_fn=<AddmmBackward>)\n",
      "predicted testing labels:\n",
      "[1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1 0\n",
      " 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 1 0 0]\n",
      "precision, recall, fbeta-score:\n",
      "(0.6574198333854986, 0.6437768240343348, 0.6332376366863929, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(96, 23, 60, 54)\n"
     ]
    }
   ],
   "source": [
    "nn_predict_train_y = model.forward( torch.FloatTensor(normalize_train_x.values.tolist()))\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 1, 0)\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(data_train_y[0], result_train))\n",
    "\n",
    "nn_predict_y = model.forward( torch.FloatTensor(normalize_test_x.values.tolist()))\n",
    "result = np.where(nn_predict_y[:, 0] > nn_predict_y[:, 1], 1, 0)\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(data_test_y[0], result))\n",
    "\n",
    "print('predicted testing prob:')\n",
    "print(nn_predict_y)\n",
    "print('predicted testing labels:')\n",
    "print(result)\n",
    "\n",
    "\n",
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(data_test_y[0], result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(data_test_y[0], result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
